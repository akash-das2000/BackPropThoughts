<style>
  /* Put your styles here */
  .tldr{
    border: 2px solid #4f81ff;
    padding:1rem 1.25rem;
    border-radius:0.5rem;
    background:#f7fbff;
  }
  .tldr h2{margin-top:0}
  .tldr ol{margin-left:1.2rem}
</style>
<section>
<!-- =======================  Header   ======================= -->
<h1 id="diffusion-maths">The Mathematical Foundations of Diffusion Models <small>(A self-contained mini-monograph)</small></h1>

<!-- =======================  TL;DR box ======================= -->
<aside class="tldr">
  <h2 id="TL;DR">TL;DR</h2>
  <p>
    Diffusion models generate images in two conceptual moves:
  </p>
  <ol>
    <li>
      <strong>Corrupt&nbsp;the data.</strong>  
      Each clean image is progressively blended with analytically-tractable Gaussian noise.
    </li>
    <li>
      <strong>Learn&nbsp;the score.</strong>  
      A neural network is trainedâ€”via an ordinary mean-squared-error lossâ€”to predict the <em>gradient</em> of the log-density (the â€œscoreâ€) of every noisy distribution.
    </li>
  </ol>
  <p>
    Once that score field is known, a <em>reverse-time stochastic differential equation</em>
    (or an equivalent deterministic ODE) can be integrated to
    push pure white noise back onto the data manifoldâ€”yielding photorealistic
    images without adversarial training or intractable likelihoods.
  </p>
</aside>

  <table class="tbl">
  <!-- ============  Notation  ============ -->
  <thead>
    <tr>
      <th colspan="3">Notation Cheat-Sheet &amp; Shapes</th>
    </tr>
    <tr>
      <th>Symbol</th>
      <th>Plain-language meaning</th>
      <th>Typical shape / note</th>
    </tr>
  </thead>

  <h2 id="notations">Notations</h2>

  <tbody>
    <tr><td><code>x_0&nbsp;âˆˆ&nbsp;â„<sup>d</sup></code></td>
        <td>clean data vector (flattened image)</td>
        <td><code>d&nbsp;=&nbsp;3HW</code></td></tr>

    <tr><td><code>t&nbsp;âˆˆ&nbsp;{0,â€¦,T}</code></td>
        <td>discrete diffusion timestep</td>
        <td>integer</td></tr>

    <tr><td><code>Î±_t&nbsp;(0&lt;Î±_t&lt;1)</code></td>
        <td>retain-signal factor at step&nbsp;<code>t</code></td>
        <td>scalar</td></tr>

    <tr><td><code>ğ›¼Ì„_t&nbsp;=&nbsp;âˆ_{s=1}^{t}Î±_s</code></td>
        <td>cumulative signal survival</td>
        <td>scalar</td></tr>

    <tr><td><code>Ïƒ_t&nbsp;=&nbsp;âˆš(1âˆ’ğ›¼Ì„_t)</code></td>
        <td>total noise std-dev after step&nbsp;<code>t</code></td>
        <td>scalar</td></tr>

    <tr><td><code>Îµ&nbsp;âˆ¼&nbsp;ğ’©(0,I_d)</code></td>
        <td>fresh isotropic Gaussian noise</td>
        <td><code>â„<sup>d</sup></code></td></tr>

    <tr><td><code>p<sub>data</sub></code></td>
        <td>trueâ€”but unknownâ€”data density</td>
        <td>never written in closed form</td></tr>

    <tr><td><code>q(x_t&nbsp;|&nbsp;x_0)</code></td>
        <td>forward/noising kernel (Gaussian)</td>
        <td>analytic</td></tr>

    <tr><td><code>p_t(x_t)</code></td>
        <td>marginal noisy density after corruption</td>
        <td>unknown but samplable</td></tr>

    <tr><td><code>s_Î¸(x_t,t)</code></td>
        <td>neural network score estimator</td>
        <td>same shape as <code>x_t</code></td></tr>

    <!-- ============  Toolbox  ============ -->
    <tr><th colspan="3" style="text-align:center">Stock-the-Toolbox Facts</th></tr>

    <tr><td><strong>Gaussian&nbsp;PDF</strong></td>
        <td colspan="2">
          <code>Ï•_Î£(z)=exp(-Â½ z<sup>âŠ¤</sup>Î£<sup>âˆ’1</sup>z) / âˆš((2Ï€)<sup>d</sup> det Î£)</code>
        </td></tr>

    <tr><td><strong>Quadratic&nbsp;grad</strong></td>
        <td colspan="2"><code>âˆ‡_xâ€–xâˆ’aâ€–<sup>2</sup> = 2(xâˆ’a)</code></td></tr>

    <tr><td><strong>Chain rule for logs</strong></td>
        <td colspan="2"><code>âˆ‡ log f = (âˆ‡f) / f</code></td></tr>

    <tr><td><strong>Affineâ€“Gaussian rule</strong></td>
        <td colspan="2">
          If <code>Zâˆ¼ğ’©(0,I)</code> and <code>Y=a+BZ</code> then
          <code>Yâˆ¼ğ’©(a, B B<sup>âŠ¤</sup>)</code>.
        </td></tr>
  </tbody>
</table>

