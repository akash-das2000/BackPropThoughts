<style>
  /* Put your styles here */
  /* ----------  TL;DR call-out ---------- */
/* ----------  TL;DR call-out (greyscale theme) ---------- */
.tldr {
  border: 1px solid #c0c0c0;      /* soft grey border */
  border-radius: 0.5rem;
  padding: 1rem 1.25rem;
  background: #f5f5f5;            /* very light grey background */
  color: #333;                    /* dark grey text for readability */
}

.tldr h2 {
  margin: 0 0 0.5rem 0;
  color: #111;                    /* nearly black for the heading */
}

.tldr ol {
  margin-left: 1.3rem;
}

.tldr li strong {
  color: #000;                    /* highlight keywords in pure black */
}

/* ----------  Ensure TL;DR inline math and text wrap on mobile  ---------- */
.tldr,
.tldr p,
.tldr ol,
.tldr li {
  /* allow words, symbols, and math to break anywhere if needed */
  word-wrap: break-word;
  overflow-wrap: break-word;
  word-break: break-word;
  hyphens: auto;
  white-space: normal;
}

/* target KaTeX/MathJax inline spans if you’re using them */
.tldr .katex,
.tldr .MathJax,
.tldr span {
  display: inline-block;
  max-width: 100%;
  white-space: normal;
}

/* shrink font slightly for extra safety on very small screens */
@media (max-width: 400px) {
  .tldr {
    font-size: 0.90rem;
  }
}


/* ----------  table styling ---------- */
table.tbl{
  width:100%;
  border-collapse:collapse;
  margin:2rem 0 2.5rem 0;
  font-size:.95rem;
}
table.tbl caption{
  caption-side:top;
  font-weight:600;
  margin-bottom:.4rem;
}
table.tbl th,
table.tbl td{
  border:1px solid #d0d0d0;
  padding:.45rem .65rem;
  text-align:left;
  vertical-align:top;
}
table.tbl thead{background:#f5f7ff;}
.tbl .shape{
  font-family:"Roboto Mono",ui-monospace,monospace;
  white-space:nowrap;
}
.fact-table th{
  background:#f5f5f5;
  width:160px;
}

/* ----------  lead paragraph ---------- */
.lead{
  font-size:1.05rem;
  line-height:1.6;
  margin:1.2rem 0 2rem 0;
  color:#333;
}
.lead ul{margin:.6rem 0 .6rem 1.4rem}

/* ----------  bridge note ---------- */
.bridge{
  font-size:.95rem;
  margin:.8rem 0 1.1rem 0;
  color:#444;
}          

/* ----------  note paragraph ---------- */
.note {
  border-left: 3px solid #888;     /* subtle grey accent */
  padding: 0.6rem 1rem;
  margin: 1rem 0;
  background: #f9f9f9;             /* very light grey background */
  color: #333;                     /* dark text for readability */
  font-size: 0.97rem;
  line-height: 1.5;
}
.note strong {
  color: #000;                     /* bold keywords in pure black */
}

/* ----------  display equations ---------- */
.eq-scroll{
  display:block;
  overflow-x:auto;
  white-space:nowrap;
  text-align:center;
  margin:1.2rem auto;
  font-size:1.02rem;
}
@media(max-width:600px){
  .eq-scroll{font-size:.9rem}
  table.tbl{font-size:.9rem}
}

/* ----------  inline & block code ---------- */
code,pre{
  font-family:"Fira Code","SFMono-Regular",ui-monospace,monospace;
  font-size:.92rem;
}
code{
  background:#f3f4f6;
  color:#1a1a1a;
  padding:0 .25em;
  border-radius:4px;
}
pre{
  background:#f8f9fb;
  border:1px solid #cfd2d7;
  border-radius:6px;
  padding:.9rem 1rem;
  line-height:1.45;
  overflow-x:auto;
  margin:1.6rem 0;
}
pre code{background:none;padding:0}
@media(max-width:600px){
  pre{font-size:.82rem}
  code{font-size:.86rem}
}

/* ----------  GitHub-style code card ---------- */
.code-card{
  background:#f6f8fa;
  border:1px solid #d0d7de;
  border-radius:6px;
  overflow:hidden;
  margin:1.6rem 0;
}
.code-card .code-header{
  background:#eaeef2;
  border-bottom:1px solid #d0d7de;
  font:.75rem/1 system-ui,sans-serif;
  color:#24292f;
  padding:.45rem .9rem;
  text-transform:lowercase;
}
.code-card pre{
  margin:0;
  padding:.8rem 1rem;
  background:inherit;
  font-size:.92rem;
  white-space:pre;
}
@media(max-width:600px){
  .code-card pre{font-size:.82rem}
}
  
/* === let wide tables side-scroll on narrow screens === */
@media (max-width: 600px){
  table.tbl{
    display:block;          /* makes it a scroll container   */
    overflow-x:auto;        /* side-scroll if too wide        */
    -webkit-overflow-scrolling: touch;
  }
  table.tbl thead,
  table.tbl tbody{
    display:table;          /* keeps header & body aligned    */
    width:100%;
  }
  table.tbl th,
  table.tbl td{
    white-space:nowrap;     /* prevent ugly line wraps        */
  }
}

/* ----------  Responsive heading wraps & scaling ---------- */

/* Allow long words in headings to break */
h1, h2, h3, h4, h5, h6 {
  overflow-wrap: break-word;
  word-wrap: break-word;
  hyphens: auto;
  white-space: normal;       /* override any no-wrap */
}

/* Shrink heading text on narrow viewports */
@media (max-width: 600px) {
  h1 { font-size: 1.5rem; }
  h2 { font-size: 1.3rem; }
  h3 { font-size: 1.15rem; }
  /* you can add h4, h5 as needed */
}

/* Optional: make the entire page text flow better on mobile */
body {
  word-wrap: break-word;
  overflow-wrap: break-word;
}

/* Override scroll-to-top button on mobile so it never hangs off-screen */
#scrollTopBtn {
  /* default for desktop */
  bottom: 2rem;
  right: 2rem;
}

/* on small viewports, reduce the offsets & size */
@media (max-width: 600px) {
  #scrollTopBtn {
    bottom: 1rem !important;
    right: 1rem !important;
    padding: 0.4rem 0.6rem !important;
    font-size: 1rem !important;
    max-width: 2.5rem;    /* ensure it stays compact */
    max-height: 2.5rem;
  }
}



</style>


<section>
  <!-- ========== Blog Title ========== -->
  <h1 id="heading">
    From Brownian Motion to Discrete Diffusion: The Mathematical Foundations of DDPM
  </h1>

  <!-- ========== TL;DR Summary (no math here) ========== -->
  <aside class="tldr">
    <h2 id="TL;DR">TL;DR</h2>
    <p>
      This post traces the mathematical spine of diffusion models, building a clear path from stochastic calculus to practical algorithms:
    </p>
    <ol>
      <li><strong>Brownian motion &amp; Itô calculus:</strong> Understand how stochastic processes evolve and why (dBₜ)² = dt is key.</li>
      <li><strong>Fokker–Planck PDE:</strong> Show how SDEs induce PDEs for probability densities.</li>
      <li><strong>Reverse-time SDE:</strong> Step-by-step derivation of reverse drift from Anderson (1982) → Song et al. (2020).</li>
      <li><strong>Discrete DDPM:</strong> Derive forward noising schedule and variational ELBO.</li>
      <li><strong>Toy model:</strong> Minimal Python DDPM to visualize forward/reverse diffusion.</li>
    </ol>
    <p>
      By the end, you'll see Ho et al. (2020) as a direct descendant of stochastic calculus.
    </p>
  </aside>

  <!-- ========== Introduction Section ========== -->
  <h2 id="introduction">Introduction</h2>
  <p class="lead">
    Diffusion models progressively corrupt data with Gaussian noise and learn to reverse that process.
    Underneath lies a rich interplay of stochastic calculus, PDEs, and variational inference.
  </p>
  <p>
    This blog continues our journey from <a href="https://backpropthoughts.netlify.app/post?postId=diffusion-maths" target="_blank">the previous post on score matching</a>. Here we dive deep into:
  </p>
  <ul>
    <li>Brownian motion: why \((dB_t)^2 = dt\) is central to stochastic integrals.</li>
    <li>Fokker–Planck equation: deriving density evolution from SDEs.</li>
    <li>Reverse-time SDE: unlocking the denoising step.</li>
    <li>Discrete DDPM: bridging continuous SDEs to Ho et al.'s formulation.</li>
  </ul>
  <p class="bridge">
    Along the way, we’ll offer rigorous proofs and practical code, building a solid foundation for understanding diffusion models mathematically.
  </p>

  <!-- ========== Section 2: Brownian Motion & Quadratic Variation ========== -->
  <h2 id="brownian-motion">2. Brownian Motion &amp; Quadratic Variation</h2>

  <!-- ----- 2.1 Intuition ----- -->
  <h3 id="brownian-intuition">2.1 Intuition: Brownian Motion and Quadratic Variation</h3>
  <p class="lead">
    Brownian motion, or Wiener process, is the cornerstone of stochastic calculus.
    It describes a continuous-time random walk with independent Gaussian increments:
  </p>
  <div class="eq-scroll">
    \[
      B_{t+s} - B_t \sim \mathcal{N}(0, s),
      \quad \text{for all } s \geq 0.
    \tag{1}
    \]
  </div>
  <ul>
    <li><strong>Independent increments:</strong> Each step is independent of the past.</li>
    <li><strong>Variance scaling:</strong> \(\mathrm{Var}[B_t] = t\).</li>
  </ul>
  <p class="bridge">
    Crucially, Brownian paths are nowhere differentiable but have a well-defined quadratic variation:
  </p>
  <div class="eq-scroll">
    \[
      (dB_t)^2 = dt.
    \tag{2}
    \]
  </div>

  <!-- ----- 2.2 Proof ----- -->
  <h3 id="brownian-proof">2.2 Proof: Why \((dB_t)^2 = dt\)</h3>
  <p class="lead">
    Let’s rigorously show how quadratic variation leads to this key identity.
  </p>
  <p>
    Partition \([0, t]\) into \(n\) intervals of width \(\Delta t = t/n\). The increments:
  </p>
  <div class="eq-scroll">
    \[
      \Delta B_i = B_{t_i} - B_{t_{i-1}} \sim \mathcal{N}(0, \Delta t).
    \tag{3}
    \]
  </div>
  <p>
    The quadratic variation of \(B_t\) is:
  </p>
  <div class="eq-scroll">
    \[
      [B]_t = \lim_{n \to \infty} \sum_{i=1}^n (\Delta B_i)^2.
    \tag{4}
    \]
  </div>
  <p>
    Since \(\mathbb{E}[(\Delta B_i)^2] = \Delta t\), the expected sum:
  </p>
  <div class="eq-scroll">
    \[
      \mathbb{E}\left[\sum_{i=1}^n (\Delta B_i)^2\right] = n\Delta t = t.
    \tag{5}
    \]
  </div>
  <p class="bridge">
    As \(n \to \infty\), this converges in probability:
  </p>
  <div class="eq-scroll">
    \[
      [B]_t = t.
    \tag{6}
    \]
  </div>
  <p class="explain">
    In differential form, \((dB_t)^2 = dt\) becomes the cornerstone of Itô calculus.
  </p>

  <!-- ----- 2.3 Connection to Diffusion Models ----- -->
  <h3 id="brownian-connection">2.3 Connection to Diffusion Models</h3>
  <p class="lead">
    The identity \((dB_t)^2 = dt\) is not just an abstract feature of Brownian motion; it is the
    linchpin in the mathematics of diffusion models.
  </p>
  <p>
    Consider a stochastic differential equation (SDE):
  </p>
  <div class="eq-scroll">
    \[
      dx_t = \mu(x_t, t)\,dt + \sigma(t)\,dB_t.
    \tag{7}
    \]
  </div>
  <p>
    Here \(\mu(x_t, t)\) is the drift and \(\sigma(t)\) the diffusion coefficient. When applying Itô’s lemma:
  </p>
  <ul>
    <li><strong>\(dB_t\):</strong> contributes random noise.</li>
    <li><strong>\((dB_t)^2\):</strong> contributes deterministic drift correction via \(dt\).</li>
  </ul>
  <p class="bridge">
    Without \((dB_t)^2=dt\), the derivation of the <strong>Fokker–Planck PDE</strong> (Section 3) and the
    <strong>reverse-time SDE</strong> (Section 4) would break down.
  </p>
  <p class="note">
    <strong>Key Takeaway:</strong> \((dB_t)^2=dt\) bridges random fluctuations to smooth density evolution, enabling Gaussian marginals.
  </p>

<!-- ========== Section 3: Fokker–Planck PDE ========== -->
<h2 id="fokker-planck">3. Deriving the Fokker–Planck Equation</h2>

<p class="lead">
  The Fokker–Planck equation describes how the probability density \(p(x, t)\) of a stochastic process evolves over time.
  In diffusion models, it formalizes the forward noising process as a PDE on \(p(x,t)\).
</p>

<p>
  We begin with a general stochastic differential equation (SDE):
</p>

<div class="eq-scroll">
  \[
    dx_t = \mu(x_t, t)\,dt + \sigma(t)\,dB_t,
  \tag{8}
  \]
</div>

<p>
  where:
</p>
<ul>
  <li>\(\mu(x, t)\): drift vector field, representing deterministic dynamics.</li>
  <li>\(\sigma(t)\): scalar diffusion coefficient (assuming isotropic noise).</li>
  <li>\(dB_t\): infinitesimal Brownian increment.</li>
</ul>

<p class="bridge">
  Our goal is to derive the PDE that governs \(p(x,t)\), the probability density of \(x_t\). This involves applying Itô’s lemma to a test function \(f(x,t)\) and then using expectation.
</p>

<!-- ----- 3.1 Itô’s Lemma Expanded ----- -->
<h3 id="ito-lemma">3.1 Itô’s Lemma (Expanded)</h3>

<p class="lead">
  For a twice-differentiable scalar function \(f(x,t)\), Itô’s lemma gives the differential:
</p>

<div class="eq-scroll">
  \[
  df(x_t, t) = \partial_t f\,dt + \nabla_x f^\top dx_t + \tfrac12\,dx_t^\top \nabla_x^2 f\,dx_t.
  \tag{9}
  \]
</div>

<p>
  Substituting \(dx_t = \mu\,dt + \sigma\,dB_t\):
</p>

<div class="eq-scroll">
  \[
  \begin{aligned}
  df(x_t, t) ={} & \partial_t f\,dt + \nabla_x f^\top (\mu\,dt + \sigma\,dB_t) \\
  & + \tfrac12 (\mu\,dt + \sigma\,dB_t)^\top \nabla_x^2 f (\mu\,dt + \sigma\,dB_t).
  \end{aligned}
  \tag{10}
  \]
</div>

<p>
  Expanding the quadratic term and applying \((dB_t)^2 = dt\):
</p>

<ul>
  <li>Cross terms like \(dt\,dB_t\) are negligible (\(O(dt^{3/2})\)).</li>
  <li>The only surviving second-order term is \(\tfrac12 \sigma^2 \Delta_x f\,dt\), where \(\Delta_x f = \text{tr}(\nabla_x^2 f)\).</li>
</ul>

<p class="bridge">
  Simplifying, we get:
</p>

<div class="eq-scroll">
  \[
  df(x_t, t) = \big[\partial_t f + \mu^\top\nabla_x f + \tfrac12\sigma^2\Delta_x f\big]\,dt
  + \sigma\,\nabla_x f^\top\,dB_t.
  \tag{11}
  \]
</div>

<p class="note">
  The second-order term \(\tfrac12\sigma^2\Delta_x f\) arises from Brownian quadratic variation (\((dB_t)^2 = dt\)).
</p>

<!-- ----- 3.2 Expectation and Time Evolution ----- -->
<h3 id="expectation-evolution">3.2 Expectation and Time Evolution</h3>

<p>
  Taking expectations of both sides and using \(\mathbb{E}[dB_t] = 0\), the stochastic term drops:
</p>

<div class="eq-scroll">
  \[
  \frac{d}{dt}\,\mathbb{E}[f(x_t, t)] =
  \mathbb{E}\left[\partial_t f + \mu^\top\nabla_x f + \tfrac12\sigma^2\Delta_x f\right].
  \tag{12}
  \]
</div>

<p>
  Since \(\mathbb{E}[f(x_t, t)] = \int f(x,t)\,p(x,t)\,dx\), differentiating under the integral gives:
</p>

<div class="eq-scroll">
  \[
  \frac{d}{dt}\,\mathbb{E}[f(x,t)] =
  \int_{\mathbb{R}^d} f(x,t)\,\partial_t p(x,t)\,dx + \int_{\mathbb{R}^d} \partial_t f(x,t)\,p(x,t)\,dx.
  \tag{13}
  \]
</div>

<p class="bridge">
  Equating both expressions for \(\tfrac{d}{dt}\mathbb{E}[f]\):
</p>

<div class="eq-scroll">
  \[
  \int f\,\partial_t p\,dx + \int \partial_t f\,p\,dx
  = \int \big(\partial_t f + \mu^\top\nabla_x f + \tfrac12\sigma^2\Delta_x f\big)\,p\,dx.
  \tag{14}
  \]
</div>

<p>
  Cancelling \(\int \partial_t f\,p\,dx\) yields:
</p>

<div class="eq-scroll">
  \[
  \int f\,\partial_t p\,dx
  = \int \big(\mu^\top\nabla_x f + \tfrac12\sigma^2\Delta_x f\big)\,p\,dx.
  \tag{15}
  \]
</div>

<!-- ----- 3.3 Integration by Parts ----- -->
<h3 id="integration-parts">3.3 Integration by Parts</h3>

<p>
  Using divergence theorem and integration by parts, transfer derivatives from \(f\) to \(p\):
</p>

<div class="eq-scroll">
  \[
  \int \mu^\top\nabla_x f\,p\,dx
  = -\int f\,\nabla_x^\top(\mu p)\,dx,
  \tag{16}
  \]
</div>

<div class="eq-scroll">
  \[
  \int \tfrac12\sigma^2\Delta_x f\,p\,dx
  = -\int f\,\nabla_x^\top\left(\tfrac12\sigma^2\nabla_x p\right)\,dx.
  \tag{17}
  \]
</div>

<p class="note">
  Boundary terms vanish because \(p(x,t)\) decays to zero at infinity.
</p>

<!-- ----- 3.4 Final PDE ----- -->
<h3 id="fokker-planck-final">3.4 The Fokker–Planck PDE</h3>

<p>
  Substitute results into Eq. (15):
</p>

<div class="eq-scroll">
  \[
  \int f\,\partial_t p\,dx
  = -\int f\,\nabla_x^\top(\mu p)\,dx
    -\int f\,\nabla_x^\top\left(\tfrac12\sigma^2\nabla_x p\right)\,dx.
  \tag{18}
  \]
</div>

<p>
  Since \(f(x,t)\) is arbitrary:
</p>

<div class="eq-scroll">
  \[
  \partial_t p(x,t)
  = -\nabla_x^\top[\mu(x,t)p(x,t)]
    + \nabla_x^\top\left(\tfrac12\sigma^2(t)\nabla_x p(x,t)\right).
  \tag{19}
  \]
</div>

<p class="explain">
  This is the <strong>Fokker–Planck equation</strong>(also called the forward Kolmogorov equation).
</p>

<!-- ----- 3.5 Visual Explanation Placeholder ----- -->
<figure>
  <img src="posts/stochastic-to-diffusion/assets/figure1.png" alt="Drift and Diffusion of probability density">
  <figcaption>
    Figure 1: Evolution of probability density showing drift (left) and diffusion (right). Drift compresses or shifts densities, while diffusion spreads them out.
  </figcaption>
</figure>


<!-- ----- 3.6 Simplified Form ----- -->
<h3 id="fokker-planck-scalar">3.5 Simplified (Scalar Diffusion)</h3>
<p>
  For constant scalar \(\sigma(t)=\sigma\):
</p>

<div class="eq-scroll">
  \[
  \partial_t p
  = -\nabla_x\cdot(\mu p) + \tfrac12\sigma^2\Delta_x p.
  \tag{20}
  \]
</div>

<p class="note">
  Here, \(\nabla_x\cdot(\mu p)\) represents drift (advection), and \(\tfrac12\sigma^2\Delta_x p\) represents diffusion (smoothing).
</p>

<!-- ----- 3.7 Connection to Diffusion Models ----- -->
<h3 id="fokker-planck-why">3.6 Connection to Diffusion Models</h3>
<p class="lead">
  In diffusion models:
</p>
<ul>
  <li>The forward process is a discretization of this PDE.</li>
  <li>\(-\nabla_x\cdot(\mu p)\): Drift towards a prior (e.g., zero mean Gaussian).</li>
  <li>\(\tfrac12\sigma^2\Delta_x p\): Noise spreading probability mass over \(\mathbb{R}^d\).</li>
</ul>

<p class="bridge">
  This PDE underpins the forward noising process. Reversing it (Section 4) leads to the reverse-time SDE—the foundation of DDPMs.
</p>

<!-- ========== Section 4: Reverse-Time SDE ========== -->
<h2 id="reverse-sde">4. Deriving the Reverse-Time SDE</h2>

<p class="lead">
  The forward SDE models how noise progressively corrupts data. But in diffusion models, our goal is the reverse: we want to denoise step-by-step.
  To do this, we must derive the SDE that describes how to reverse a stochastic process in time.
  This was first rigorously derived by Anderson (1982) and later applied in diffusion models by Song et al. (2020).
</p>

<p>
  Recall the forward SDE for a stochastic process \(x_t\):
</p>

<div class="eq-scroll">
  \[
    dx_t = \mu(x_t, t)\,dt + \sigma(t)\,dB_t,
  \tag{20}
  \]
</div>

<p>
  where:
</p>
<ul>
  <li>\(\mu(x, t)\): drift term (deterministic dynamics)</li>
  <li>\(\sigma(t)\): diffusion coefficient (strength of noise)</li>
  <li>\(dB_t\): Brownian motion increment</li>
</ul>

<p class="bridge">
  We now derive the SDE governing \(x_t\) when time is reversed from \(t=T\) to \(t=0\).
</p>

<!-- ----- 4.1 Probability flow perspective ----- -->
<h3 id="probability-flow">4.1 Probability Flow Perspective</h3>
<p class="lead">
  To reverse a stochastic process, we need to reverse not just trajectories but also probability densities \(p(x,t)\).
</p>

<p>
  The probability density evolution is governed by the Fokker–Planck PDE (Eq. (18)):
</p>

<div class="eq-scroll">
  \[
    \partial_t p(x,t) = -\nabla_x\cdot(\mu(x,t)p(x,t)) + \tfrac12\sigma^2(t)\Delta_x p(x,t).
  \tag{21}
  \]
</div>

<p class="note">
  Reversing time means finding the dynamics that result in \(p(x,t)\) evolving backward: from \(p(x,T)\) to \(p(x,0)\).
</p>

<p class="bridge">
  Anderson’s key insight was to adjust the drift term so that the reverse process preserves the same probability trajectories in reverse order.
</p>

<!-- ----- 4.2 Derivation of Reverse Drift ----- -->
<h3 id="reverse-drift-derivation">4.2 Derivation of the Reverse Drift (Anderson 1982)</h3>
<p>
  Let \(\tilde{\mu}(x,t)\) denote the drift of the reverse-time process. It can be shown:
</p>

<div class="eq-scroll">
  \[
    \tilde{\mu}(x,t) = \mu(x,t) - \sigma^2(t)\nabla_x\log p(x,t).
  \tag{22}
  \]
</div>

<p class="lead">
  <strong>Derivation:</strong> Start by writing the forward Fokker–Planck equation in divergence form:
</p>

<div class="eq-scroll">
  \[
    \partial_t p = -\nabla_x\cdot(\mu p) + \tfrac12\sigma^2\Delta_x p.
  \tag{23}
  \]
</div>

<p>
  Under time reversal (\(t \to T - t\)), we define the reverse-time density \(\tilde{p}(x,t) = p(x, T - t)\).
  The reverse-time Fokker–Planck equation becomes:
</p>

<div class="eq-scroll">
  \[
    \partial_t \tilde{p} = -\nabla_x\cdot(\tilde{\mu}\tilde{p}) + \tfrac12\sigma^2(t)\Delta_x\tilde{p}.
  \tag{24}
  \]
</div>

<p>
  Comparing Eq. (23) and Eq. (24) leads to the condition:
</p>

<div class="eq-scroll">
  \[
    \tilde{\mu}(x,t)\tilde{p}(x,t) = \mu(x,t)\tilde{p}(x,t) - \sigma^2(t)\nabla_x\tilde{p}(x,t).
  \tag{25}
  \]
</div>

<p>
  Divide both sides by \(\tilde{p}(x,t)\) (assuming \(\tilde{p}(x,t) > 0\)):
</p>

<div class="eq-scroll">
  \[
    \tilde{\mu}(x,t) = \mu(x,t) - \sigma^2(t)\nabla_x\log\tilde{p}(x,t).
  \tag{26}
  \]
</div>

<p class="explain">
  Since \(\tilde{p}(x,t) = p(x,T - t)\), we obtain Eq. (22).
</p>

<!-- ----- 4.3 Final Reverse SDE ----- -->
<h3 id="reverse-sde-final">4.3 The Reverse-Time SDE</h3>
<p class="lead">
  Substituting \(\tilde{\mu}(x,t)\) back gives the reverse-time SDE:
</p>

<div class="eq-scroll">
  \[
    dx_t = \left[\mu(x,t) - \sigma^2(t)\nabla_x\log p(x,t)\right]dt + \sigma(t)d\bar{B}_t,
  \tag{27}
  \]
</div>

<p>
  where \(d\bar{B}_t\) is Brownian motion in reverse time (with inverted increments).
</p>

<p class="note">
  The reverse drift contains a score function \(-\nabla_x\log p(x,t)\), which must be estimated in practice.
</p>

<!-- ----- 4.4 Connection to Diffusion Models ----- -->
<h3 id="reverse-sde-diffusion">4.4 Connection to Diffusion Models (Song et al. 2020)</h3>
<p>
  In diffusion models:
</p>
<ul>
  <li>The forward process progressively adds Gaussian noise.</li>
  <li>The reverse process uses a neural network to approximate the score function \(\nabla_x\log p(x,t)\).</li>
</ul>

<p class="bridge">
  Song et al. (2020) discretize Eq. (27) and learn \(-\nabla_x\log p(x,t)\) via score-matching. This forms the basis of denoising diffusion probabilistic models (DDPMs).
</p>

<p class="explain">
  Each step in the learned reverse process approximates sampling from the true posterior \(p(x_{t-1}|x_t)\).
</p>

<!-- ----- 4.4 Visual Explanation Placeholder ----- -->
<figure>
  <img src="posts/stochastic-to-diffusion/assets/figure2.png" alt="Forward and reverse-time SDE illustration">
  <figcaption>
    Figure 2: Visual representation of the forward SDE \(dx_t = \mu(x,t)\,dt + \sigma(t)\,dB_t\) (left) and the reverse-time SDE \(dx_t = [\mu(x,t) - \sigma^2(t)\nabla_x\log p(x,t)]dt + \sigma(t)dB_t\) (right).
  </figcaption>
</figure>


<!-- ----- 4.5 Summary ----- -->
<h3 id="reverse-sde-summary">4.5 Summary</h3>
<p class="lead">
  The reverse-time SDE is the mathematical backbone of DDPMs. It connects stochastic calculus (Anderson, 1982) with modern generative modeling (Song et al., 2020).
</p>

<p class="note">
  <strong>Key Insight:</strong> The correction term \(-\sigma^2(t)\nabla_x\log p(x,t)\) guides noisy samples back to the data manifold.
</p>

