<style>
  /* Put your styles here */
  /* ----------  TL;DR call-out ---------- */
/* ----------  TL;DR call-out (greyscale theme) ---------- */
.tldr {
  border: 1px solid #c0c0c0;      /* soft grey border */
  border-radius: 0.5rem;
  padding: 1rem 1.25rem;
  background: #f5f5f5;            /* very light grey background */
  color: #333;                    /* dark grey text for readability */
}

.tldr h2 {
  margin: 0 0 0.5rem 0;
  color: #111;                    /* nearly black for the heading */
}

.tldr ol {
  margin-left: 1.3rem;
}

.tldr li strong {
  color: #000;                    /* highlight keywords in pure black */
}

/* ----------  Ensure TL;DR inline math and text wrap on mobile  ---------- */
.tldr,
.tldr p,
.tldr ol,
.tldr li {
  /* allow words, symbols, and math to break anywhere if needed */
  word-wrap: break-word;
  overflow-wrap: break-word;
  word-break: break-word;
  hyphens: auto;
  white-space: normal;
}

/* target KaTeX/MathJax inline spans if you’re using them */
.tldr .katex,
.tldr .MathJax,
.tldr span {
  display: inline-block;
  max-width: 100%;
  white-space: normal;
}

/* shrink font slightly for extra safety on very small screens */
@media (max-width: 400px) {
  .tldr {
    font-size: 0.90rem;
  }
}


/* ----------  table styling ---------- */
table.tbl{
  width:100%;
  border-collapse:collapse;
  margin:2rem 0 2.5rem 0;
  font-size:.95rem;
}
table.tbl caption{
  caption-side:top;
  font-weight:600;
  margin-bottom:.4rem;
}
table.tbl th,
table.tbl td{
  border:1px solid #d0d0d0;
  padding:.45rem .65rem;
  text-align:left;
  vertical-align:top;
}
table.tbl thead{background:#f5f7ff;}
.tbl .shape{
  font-family:"Roboto Mono",ui-monospace,monospace;
  white-space:nowrap;
}
.fact-table th{
  background:#f5f5f5;
  width:160px;
}

/* ----------  lead paragraph ---------- */
.lead{
  font-size:1.05rem;
  line-height:1.6;
  margin:1.2rem 0 2rem 0;
  color:#333;
}
.lead ul{margin:.6rem 0 .6rem 1.4rem}

/* ----------  bridge note ---------- */
.bridge{
  font-size:.95rem;
  margin:.8rem 0 1.1rem 0;
  color:#444;
}          

/* ----------  note paragraph ---------- */
.note {
  border-left: 3px solid #888;     /* subtle grey accent */
  padding: 0.6rem 1rem;
  margin: 1rem 0;
  background: #f9f9f9;             /* very light grey background */
  color: #333;                     /* dark text for readability */
  font-size: 0.97rem;
  line-height: 1.5;
}
.note strong {
  color: #000;                     /* bold keywords in pure black */
}

/* ----------  display equations ---------- */
.eq-scroll{
  display:block;
  overflow-x:auto;
  white-space:nowrap;
  text-align:center;
  margin:1.2rem auto;
  font-size:1.02rem;
}
@media(max-width:600px){
  .eq-scroll{font-size:.9rem}
  table.tbl{font-size:.9rem}
}

/* ----------  inline & block code ---------- */
code,pre{
  font-family:"Fira Code","SFMono-Regular",ui-monospace,monospace;
  font-size:.92rem;
}
code{
  background:#f3f4f6;
  color:#1a1a1a;
  padding:0 .25em;
  border-radius:4px;
}
pre{
  background:#f8f9fb;
  border:1px solid #cfd2d7;
  border-radius:6px;
  padding:.9rem 1rem;
  line-height:1.45;
  overflow-x:auto;
  margin:1.6rem 0;
}
pre code{background:none;padding:0}
@media(max-width:600px){
  pre{font-size:.82rem}
  code{font-size:.86rem}
}

/* ----------  GitHub-style code card ---------- */
.code-card{
  background:#f6f8fa;
  border:1px solid #d0d7de;
  border-radius:6px;
  overflow:hidden;
  margin:1.6rem 0;
}
.code-card .code-header{
  background:#eaeef2;
  border-bottom:1px solid #d0d7de;
  font:.75rem/1 system-ui,sans-serif;
  color:#24292f;
  padding:.45rem .9rem;
  text-transform:lowercase;
}
.code-card pre{
  margin:0;
  padding:.8rem 1rem;
  background:inherit;
  font-size:.92rem;
  white-space:pre;
}
@media(max-width:600px){
  .code-card pre{font-size:.82rem}
}
  
/* === let wide tables side-scroll on narrow screens === */
@media (max-width: 600px){
  table.tbl{
    display:block;          /* makes it a scroll container   */
    overflow-x:auto;        /* side-scroll if too wide        */
    -webkit-overflow-scrolling: touch;
  }
  table.tbl thead,
  table.tbl tbody{
    display:table;          /* keeps header & body aligned    */
    width:100%;
  }
  table.tbl th,
  table.tbl td{
    white-space:nowrap;     /* prevent ugly line wraps        */
  }
}

/* ----------  Responsive heading wraps & scaling ---------- */

/* Allow long words in headings to break */
h1, h2, h3, h4, h5, h6 {
  overflow-wrap: break-word;
  word-wrap: break-word;
  hyphens: auto;
  white-space: normal;       /* override any no-wrap */
}

/* Shrink heading text on narrow viewports */
@media (max-width: 600px) {
  h1 { font-size: 1.5rem; }
  h2 { font-size: 1.3rem; }
  h3 { font-size: 1.15rem; }
  /* you can add h4, h5 as needed */
}

/* Optional: make the entire page text flow better on mobile */
body {
  word-wrap: break-word;
  overflow-wrap: break-word;
}

/* Override scroll-to-top button on mobile so it never hangs off-screen */
#scrollTopBtn {
  /* default for desktop */
  bottom: 2rem;
  right: 2rem;
}

/* on small viewports, reduce the offsets & size */
@media (max-width: 600px) {
  #scrollTopBtn {
    bottom: 1rem !important;
    right: 1rem !important;
    padding: 0.4rem 0.6rem !important;
    font-size: 1rem !important;
    max-width: 2.5rem;    /* ensure it stays compact */
    max-height: 2.5rem;
  }
}



</style>


<!-- ========== Blog Title ========== -->
<h1 id="heading">
  Continuous-Time Diffusion Models: SDE Formulations and Variational Objectives
</h1>

<!-- ========== TL;DR Summary (plain inline equations) ========== -->
<aside class="tldr">
  <h2 id="TL;DR">TL;DR</h2>
  <p>
    This post extends our mathematical journey into diffusion models, moving beyond discrete timesteps to a continuous-time framework:
  </p>
  <ol>
    <li><strong>Continuous SDEs:</strong> Generalize discrete forward/reverse processes to stochastic differential equations of the form dx_t = f(x, t) dt + g(t) dB_t.</li>
    <li><strong>Noise Schedules:</strong> Map variance schedules beta(t) to drift and diffusion coefficients.</li>
    <li><strong>Variational Objectives:</strong> Derive a continuous-time ELBO using Girsanov’s theorem and connect it to the Fisher information integral.</li>
    <li><strong>Score Matching:</strong> Interpret the loss as continuous-time score matching for learning nabla_x log p_t(x).</li>
    <li><strong>Outlook:</strong> Preview Predictor–Corrector samplers and deterministic probability flow ODEs for faster sampling.</li>
  </ol>
  <p>
    By the end, you’ll see how Song et al. (2021)’s framework unifies diffusion models under elegant continuous-time dynamics.
  </p>
</aside>

<!-- ========== Introduction Section ========== -->
<h2 id="introduction">Introduction</h2>
<p class="lead">
  In our <a href="https://backpropthoughts.netlify.app/post?postId=stochastic-to-diffusion" target="_blank">previous post</a>, we traced the mathematical spine of diffusion models—from Brownian motion and Itô calculus to the discrete Denoising Diffusion Probabilistic Models (DDPM) framework. We derived the forward and reverse stochastic differential equations (SDEs), explored their connection to the Fokker–Planck PDE, and built up to the variational ELBO that makes DDPMs trainable in practice.
</p>

<p>
  To fully appreciate these ideas, it helps to recall our earlier post on 
  <a href="https://backpropthoughts.netlify.app/post?postId=diffusion-maths" target="_blank">denoising score matching</a>, where we examined how noise prediction relates to estimating the gradient of the data log-density. These insights form the foundation for the continuous-time perspective.
</p>

<p>
  While discrete diffusion models like DDPM are powerful, their reliance on fixed timesteps can be limiting. This motivates the transition to <strong>continuous-time diffusion models</strong>, where stochastic processes evolve in an unbroken time interval and neural networks learn to approximate the score function across all \(t \in [0, T]\).
</p>

<p class="bridge">
  In this post, we build on these foundations and dive into the continuous-time formulation. We will derive forward and reverse SDEs, map noise schedules \(\beta(t)\) to drift and diffusion coefficients, and show how Girsanov’s theorem leads naturally to a continuous-time ELBO. Along the way, we’ll see how the Fisher information emerges in this setting and why score-based generative models are a natural generalization of DDPMs.
</p>


<!-- ========== Section: Forward and Reverse SDEs ========== -->
<h2 id="forward-reverse-sdes">Forward and Reverse SDEs</h2>

<p class="lead">
  In the <a href="https://backpropthoughts.netlify.app/post?postId=stochastic-to-diffusion" target="_blank">previous post</a>, we derived both the forward and reverse stochastic differential equations (SDEs) that form the backbone of diffusion models. Let’s briefly revisit these results to set the stage for continuous-time formulations.
</p>

<!-- ----- Forward SDE ----- -->
<h3 id="forward-sde">Forward SDE</h3>
<p>
  The forward diffusion process incrementally perturbs a clean data sample \(x_0\) by adding Gaussian noise at each timestep. In the continuous-time limit, this is modeled by the SDE:
</p>

<div class="eq-scroll">
  dx_t = f(x, t) dt + g(t) dB_t
</div>

<p>
  Here:
</p>
<ul>
  <li><strong>f(x, t):</strong> Drift function, capturing deterministic dynamics.</li>
  <li><strong>g(t):</strong> Diffusion coefficient, controlling the noise level.</li>
  <li><strong>dB_t:</strong> Brownian motion increment.</li>
</ul>

<p class="bridge">
  For a step-by-step derivation of this SDE from discrete Gaussian perturbations, see Section 2 of the <a href="https://backpropthoughts.netlify.app/post?postId=stochastic-to-diffusion" target="_blank">previous blog</a>.
</p>


<!-- ----- Reverse SDE ----- -->
<h3 id="reverse-sde">Reverse SDE</h3>
<p>
  To reverse the corruption process, we derived the reverse-time SDE (Anderson, 1982):
</p>

<div class="eq-scroll">
  dx_t = [f(x, t) - g(t)^2 ∇_x log p_t(x)] dt + g(t) dB̄_t
</div>

<p>
  The key insight is the additional drift term \(-g(t)^2 ∇_x log p_t(x)\), which steers noisy samples back toward high-density regions of the data distribution. In practice, we approximate \(\nabla_x \log p_t(x)\) with a neural network \(s_θ(x, t)\) trained via score matching.
</p>

<p class="note">
  For the full derivation of this reverse SDE using the Fokker–Planck PDE and Itô calculus, refer to Section 4 in the <a href="https://backpropthoughts.netlify.app/post?postId=stochastic-to-diffusion" target="_blank">previous post</a>.
</p>

<!-- ========== Section: Noise Schedules and Drift/Diffusion Coefficients ========== -->
<h2 id="noise-schedules">Noise Schedules and Drift/Diffusion Coefficients</h2>

<p class="lead">
  In discrete diffusion models like DDPM, we define a variance schedule \(\{\beta_t\}\) to control how much noise is added at each timestep. As we transition to continuous-time models, we replace this with a smooth function \(\beta(t)\) defined for \(t \in [0, T]\). This section shows how \(\beta(t)\) determines the drift \(f(x, t)\) and diffusion coefficient \(g(t)\) in the forward SDE.
</p>

<p>
  Recall the continuous forward SDE:
</p>

<div class="eq-scroll">
  \[
    dx_t = f(x, t)\,dt + g(t)\,dB_t
  \]
</div>

<p>
  In most diffusion models, the drift is chosen to keep the process isotropic and centered, leading to:
</p>

<div class="eq-scroll">
  \[
    f(x, t) = -\tfrac{1}{2}\,\beta(t)\,x
  \]
</div>

<p>
  The diffusion coefficient \(g(t)\) relates directly to \(\beta(t)\):
</p>

<div class="eq-scroll">
  \[
    g(t) = \sqrt{\beta(t)}
  \]
</div>

<p class="bridge">
  Let’s derive these relationships starting from the discrete variance schedule.
</p>

<!-- ----- 3.1 From Discrete to Continuous ----- -->
<h3 id="discrete-to-continuous">3.1 From Discrete to Continuous</h3>
<p class="lead">
  In DDPM, the forward process is defined as:
</p>

<div class="eq-scroll">
  \[
    x_t = \sqrt{1 - \beta_t}\,x_{t-1} + \sqrt{\beta_t}\,\epsilon_t,\quad \epsilon_t \sim \mathcal{N}(0, I)
  \]
</div>

<p>
  For small \(\beta_t\), expand \(\sqrt{1 - \beta_t}\) using a first-order Taylor approximation:
</p>

<div class="eq-scroll">
  \[
    \sqrt{1 - \beta_t} \approx 1 - \tfrac{1}{2}\,\beta_t
  \]
</div>

<p>
  Substituting back, we get:
</p>

<div class="eq-scroll">
  \[
    x_t - x_{t-1} \approx -\tfrac{1}{2}\,\beta_t\,x_{t-1} + \sqrt{\beta_t}\,\epsilon_t
  \]
</div>

<p>
  Dividing both sides by \(\Delta t\) (where \(\Delta t = 1/T\), the timestep size) and taking the limit \(\Delta t \to 0\), we obtain the continuous-time forward SDE:
</p>

<div class="eq-scroll">
  \[
    dx_t = -\tfrac{1}{2}\,\beta(t)\,x_t\,dt + \sqrt{\beta(t)}\,dB_t
  \]
</div>

<details>
  <summary><strong>Step-by-step derivation</strong></summary>
  <p>
    Starting from the discrete update:
  </p>

  <div class="eq-scroll">
    \[
      x_t = \sqrt{1 - \beta_t}\,x_{t-1} + \sqrt{\beta_t}\,\epsilon_t
    \]
  </div>

  <p>
    Approximate \(\sqrt{1 - \beta_t} \approx 1 - \tfrac{1}{2}\,\beta_t\):
  </p>

  <div class="eq-scroll">
    \[
      x_t \approx (1 - \tfrac{1}{2}\,\beta_t)\,x_{t-1} + \sqrt{\beta_t}\,\epsilon_t
    \]
  </div>

  <p>
    Simplify:
  </p>

  <div class="eq-scroll">
    \[
      x_t - x_{t-1} \approx -\tfrac{1}{2}\,\beta_t\,x_{t-1} + \sqrt{\beta_t}\,\epsilon_t
    \]
  </div>

  <p>
    Divide by \(\Delta t\) and recognize the limits:
  </p>

  <div class="eq-scroll">
    \[
      \frac{x_t - x_{t-1}}{\Delta t} \to \frac{dx_t}{dt},\quad \frac{\sqrt{\beta_t}}{\sqrt{\Delta t}} \to \sqrt{\beta(t)}
    \]
  </div>

  <p>
    Resulting in:
  </p>

  <div class="eq-scroll">
    \[
      dx_t = -\tfrac{1}{2}\,\beta(t)\,x_t\,dt + \sqrt{\beta(t)}\,dB_t
    \]
  </div>
</details>

<p class="note">
  <strong>Key Insight:</strong> The drift term \(-\tfrac{1}{2}\,\beta(t)\,x_t\) pulls samples toward the origin, while the diffusion term \(\sqrt{\beta(t)}\) injects Gaussian noise.
</p>



<!-- ----- 3.2 Common Noise Schedules ----- -->
<h3 id="common-schedules">3.2 Common Noise Schedules</h3>
<p class="lead">
  The choice of \(\beta(t)\) profoundly affects training stability and sample quality. Common schedules include:
</p>

<ul>
  <li><strong>Linear:</strong> \(\beta(t)\) increases linearly from \(\beta_0\) to \(\beta_1\).</li>
  <li><strong>Cosine:</strong> \(\beta(t)\) follows a cosine curve for smoother noise accumulation (Nichol & Dhariwal, 2021).</li>
  <li><strong>Exponential:</strong> \(\beta(t) = \beta_0\,e^{\lambda t}\)</li>
</ul>

<p>
  Visualizing \(\beta(t)\) and the resulting diffusion coefficient \(g(t) = \sqrt{\beta(t)}\) helps understand their impact.
</p>

<figure>
  <img src="posts/continious-time-diffuision-models/assets/figure1.png" alt="Examples of noise schedules β(t)">
  <figcaption>
    <strong>Figure 1:</strong> Common noise schedules used in continuous-time diffusion models. Linear schedules steadily increase noise, while cosine schedules emphasize early timesteps.
  </figcaption>
</figure>

<p class="note">
  <strong>Takeaway:</strong> Carefully designing \(\beta(t)\) balances noise injection across time, crucial for stable training.
</p>

<!-- ========== Section: Training Objective in Continuous Time ========== -->
<h2 id="training-objective">Training Objective in Continuous Time</h2>

<p class="lead">
  In discrete diffusion models, we derived the variational lower bound (ELBO) using KL divergences between Gaussian distributions at each timestep. In continuous-time diffusion models, the derivation requires more advanced tools from stochastic calculus—specifically <strong>Girsanov’s theorem</strong>—to handle the change of measure between the forward and reverse SDEs.
</p>

<p>
  Recall the forward SDE:
</p>

<div class="eq-scroll">
  \[
    dx_t = f(x, t)\,dt + g(t)\,dB_t
  \]
</div>

<p>
  and the reverse SDE:
</p>

<div class="eq-scroll">
  \[
    dx_t = \big[f(x, t) - g(t)^2 \nabla_x \log p_t(x)\big]\,dt + g(t)\,d\bar{B}_t
  \]
</div>

<p class="bridge">
  Our goal is to find a tractable objective for training a neural network \(s_\theta(x, t) \approx \nabla_x \log p_t(x)\) that approximates the score function.
</p>



<!-- ----- 4.1 Girsanov’s Theorem ----- -->
<h3 id="girsanov-theorem">4.1 Girsanov’s Theorem</h3>
<p class="lead">
  Girsanov’s theorem provides the Radon–Nikodym derivative (likelihood ratio) between two probability measures induced by different SDEs.
</p>

<p>
  Consider two SDEs with the same diffusion coefficient \(g(t)\):
</p>

<div class="eq-scroll">
  \[
    dx_t = f(x, t)\,dt + g(t)\,dB_t
  \]
</div>

<p>
  and
</p>

<div class="eq-scroll">
  \[
    dx_t = \tilde{f}(x, t)\,dt + g(t)\,d\tilde{B}_t
  \]
</div>

<p>
  Girsanov’s theorem tells us:
</p>

<div class="eq-scroll">
  \[
    \frac{d\mathbb{Q}}{d\mathbb{P}} = \exp\left(
      \int_0^T \frac{\tilde{f}(x, t) - f(x, t)}{g(t)}\,dB_t
      - \frac{1}{2} \int_0^T \left\|\frac{\tilde{f}(x, t) - f(x, t)}{g(t)}\right\|^2 dt
    \right)
  \]
</div>

<details>
  <summary><strong>Step-by-step derivation of likelihood ratio</strong></summary>
  <p>
    Starting from the two SDEs, we write their increments:
  </p>

  <div class="eq-scroll">
    \[
      dx_t = f(x, t)\,dt + g(t)\,dB_t,\quad
      dx_t = \tilde{f}(x, t)\,dt + g(t)\,d\tilde{B}_t
    \]
  </div>

  <p>
    Since \(g(t)\) is the same, the difference in drift can be expressed as:
  </p>

  <div class="eq-scroll">
    \[
      \delta(x, t) = \frac{\tilde{f}(x, t) - f(x, t)}{g(t)}
    \]
  </div>

  <p>
    Girsanov’s theorem then gives:
  </p>

  <div class="eq-scroll">
    \[
      \frac{d\mathbb{Q}}{d\mathbb{P}} = \exp\left(\int_0^T \delta(x, t)\,dB_t - \tfrac{1}{2}\int_0^T \|\delta(x, t)\|^2 dt\right)
    \]
  </div>
</details>

<p class="note">
  <strong>Key Insight:</strong> This change-of-measure forms the backbone of continuous-time variational objectives.
</p>



<!-- ----- 4.2 ELBO Derivation ----- -->
<h3 id="elbo-derivation">4.2 ELBO Derivation</h3>
<p class="lead">
  To train the reverse model, we seek to minimize the KL divergence between the true forward process \(q\) and the parameterized reverse process \(p_\theta\):
</p>

<div class="eq-scroll">
  \[
    \mathrm{KL}(q \| p_\theta) = \mathbb{E}_{q}\left[\log\frac{q(x_{0:T})}{p_\theta(x_{0:T})}\right]
  \]
</div>

<p>
  Using Girsanov’s theorem, we express this as:
</p>

<div class="eq-scroll">
  \[
    \mathrm{KL}(q \| p_\theta) = \mathbb{E}_{q}\left[\tfrac{1}{2}\int_0^T \left\|s_\theta(x, t) - \nabla_x \log p_t(x)\right\|^2 g(t)^2 dt\right] + \mathrm{const.}
  \]
</div>

<p class="bridge">
  This term measures how well the neural network \(s_\theta(x, t)\) approximates the score function \(\nabla_x \log p_t(x)\).
</p>



<!-- ----- 4.3 Fisher Information Integral ----- -->
<h3 id="fisher-information">4.3 Fisher Information Integral</h3>
<p class="lead">
  Notice the appearance of the Fisher information:
</p>

<div class="eq-scroll">
  \[
    \int_0^T g(t)^2 \mathbb{E}_{p_t(x)}\left[\left\|s_\theta(x, t) - \nabla_x \log p_t(x)\right\|^2\right] dt
  \]
</div>

<p>
  This integral captures the expected squared error between the predicted and true scores, weighted by the diffusion strength \(g(t)^2\).
</p>

<p class="note">
  <strong>Key Takeaway:</strong> Minimizing this term is equivalent to matching the score function at all times, leading to effective denoising.
</p>



<!-- ----- 4.4 Summary ----- -->
<h3 id="objective-summary">4.4 Summary</h3>
<p class="lead">
  The continuous-time training objective elegantly unifies stochastic calculus and variational inference. Using Girsanov’s theorem, we arrive at a loss function that encourages the neural network to predict the score function \(\nabla_x \log p_t(x)\) across all timesteps.
</p>

<figure>
  <img src="posts/continiuous-diffusion/assets/figure2.png" alt="Continuous-time ELBO schematic">
  <figcaption>
    <strong>Figure 2:</strong> Schematic of the continuous-time ELBO derived via Girsanov’s theorem.
  </figcaption>
</figure>

<!-- ========== Section: Implications for Score Matching ========== -->
<h2 id="score-matching">Implications for Score Matching</h2>

<p class="lead">
  The continuous-time training objective derived in the previous section elegantly connects diffusion models to <strong>denoising score matching</strong>—a concept first proposed by Vincent (2011). Let’s unpack this connection step by step.
</p>

<p>
  Recall our variational loss derived via Girsanov’s theorem:
</p>

<div class="eq-scroll">
  \[
    L(\theta) = \int_0^T g(t)^2\, \mathbb{E}_{p_t(x)}\left[\|s_\theta(x, t) - \nabla_x \log p_t(x)\|^2\right]\,dt
  \]
</div>

<p>
  This objective aims to match the network prediction \(s_\theta(x, t)\) to the true score function \(\nabla_x \log p_t(x)\) at every time \(t\), weighted by the diffusion strength \(g(t)^2\).
</p>



<h3 id="score-matching-recap">5.1 Score Matching Recap</h3>
<p class="lead">
  Score matching seeks to minimize the expected squared error between the model’s score estimate and the true score:
</p>

<div class="eq-scroll">
  \[
    \mathcal{J}(\theta) = \mathbb{E}_{p(x)}\left[\|\nabla_x \log p(x) - s_\theta(x)\|^2\right]
  \]
</div>

<p>
  We explored this concept in depth in our earlier post on 
  <a href="https://backpropthoughts.netlify.app/post?postId=diffusion-maths" target="_blank">
    denoising score matching
  </a>. In diffusion models, the idea extends naturally across a continuum of noise levels \(t \in [0, T]\).
</p>

<p class="bridge">
  But how exactly does the diffusion process lead to score matching? The key lies in the parameterization of the reverse drift and the change of measure.
</p>




<!-- ----- 5.2 Derivation: From ELBO to Score Matching ----- -->
<h3 id="elbo-to-score-matching">5.2 From ELBO to Score Matching</h3>
<p class="lead">
  Let’s expand the variational objective step by step.
</p>

<details>
  <summary><strong>Step-by-step derivation</strong></summary>

  <p>
    Start from the KL divergence between the true process \(q(x_{0:T})\) and the reverse process \(p_\theta(x_{0:T})\):
  </p>

  <div class="eq-scroll">
    \[
      \mathrm{KL}(q \| p_\theta) = \mathbb{E}_q\left[\log\frac{q(x_{0:T})}{p_\theta(x_{0:T})}\right]
    \]
  </div>

  <p>
    Using Girsanov’s theorem, the likelihood ratio simplifies to:
  </p>

  <div class="eq-scroll">
    \[
      \log\frac{q(x_{0:T})}{p_\theta(x_{0:T})} = \frac{1}{2}\int_0^T \|s_\theta(x, t) - \nabla_x \log p_t(x)\|^2 g(t)^2\,dt + C
    \]
  </div>

  <p>
    Here \(C\) is a constant independent of \(\theta\).
  </p>

  <p>
    Taking expectations gives:
  </p>

  <div class="eq-scroll">
    \[
      L(\theta) = \frac{1}{2}\int_0^T g(t)^2\,\mathbb{E}_{p_t(x)}\left[\|s_\theta(x, t) - \nabla_x \log p_t(x)\|^2\right]\,dt + C
    \]
  </div>

  <p>
    Thus, minimizing \(L(\theta)\) is equivalent to matching the predicted score \(s_\theta(x, t)\) to the true score \(\nabla_x \log p_t(x)\) across all time \(t\).
  </p>
</details>

<p class="note">
  <strong>Insight:</strong> The continuous-time loss integrates the score matching error over the diffusion trajectory.
</p>



<!-- ----- 5.3 Discrete DDPM Loss Connection ----- -->
<h3 id="discrete-ddpm-loss">5.3 Discrete DDPM Loss Connection</h3>
<p class="lead">
  Recall the simplified DDPM loss in Ho et al. (2020):
</p>

<div class="eq-scroll">
  \[
    L_{\text{simple}}(\theta) = \mathbb{E}_{t, x_0, \epsilon}\left[
      \|\epsilon - \epsilon_\theta(x_t, t)\|^2
    \right]
  \]
</div>

<p>
  Here, \(\epsilon_\theta(x_t, t)\) predicts the noise added at timestep \(t\). This is a special case of score matching, since:
</p>

<div class="eq-scroll">
  \[
    \epsilon = -g(t)\,\nabla_x \log p_t(x) + \mathcal{N}(0, I)
  \]
</div>

<p>
  Hence, training \(\epsilon_\theta\) to predict \(\epsilon\) indirectly learns the score \(\nabla_x \log p_t(x)\).
</p>

<p class="bridge">
  In the continuous-time case, we learn \(s_\theta(x, t)\) directly instead of going through \(\epsilon\).
</p>



<!-- ----- 5.4 Summary ----- -->
<h3 id="score-matching-summary">5.4 Summary</h3>
<p class="lead">
  The continuous-time objective derived from variational inference naturally reduces to denoising score matching. By learning the score function \(\nabla_x \log p_t(x)\) across all noise levels, the model can effectively reverse the diffusion process.
</p>

<p class="note">
  <strong>Key Takeaway:</strong> Continuous-time diffusion models unify stochastic calculus and score-based learning under a single elegant loss function.
</p>
