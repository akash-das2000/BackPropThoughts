<style>
  /* Put your styles here */
  /* ----------  TL;DR call-out ---------- */
/* ----------  TL;DR call-out (greyscale theme) ---------- */
.tldr {
  border: 1px solid #c0c0c0;      /* soft grey border */
  border-radius: 0.5rem;
  padding: 1rem 1.25rem;
  background: #f5f5f5;            /* very light grey background */
  color: #333;                    /* dark grey text for readability */
}

.tldr h2 {
  margin: 0 0 0.5rem 0;
  color: #111;                    /* nearly black for the heading */
}

.tldr ol {
  margin-left: 1.3rem;
}

.tldr li strong {
  color: #000;                    /* highlight keywords in pure black */
}

/* ----------  Ensure TL;DR inline math and text wrap on mobile  ---------- */
.tldr,
.tldr p,
.tldr ol,
.tldr li {
  /* allow words, symbols, and math to break anywhere if needed */
  word-wrap: break-word;
  overflow-wrap: break-word;
  word-break: break-word;
  hyphens: auto;
  white-space: normal;
}

/* target KaTeX/MathJax inline spans if you’re using them */
.tldr .katex,
.tldr .MathJax,
.tldr span {
  display: inline-block;
  max-width: 100%;
  white-space: normal;
}

/* shrink font slightly for extra safety on very small screens */
@media (max-width: 400px) {
  .tldr {
    font-size: 0.90rem;
  }
}


/* ----------  table styling ---------- */
table.tbl{
  width:100%;
  border-collapse:collapse;
  margin:2rem 0 2.5rem 0;
  font-size:.95rem;
}
table.tbl caption{
  caption-side:top;
  font-weight:600;
  margin-bottom:.4rem;
}
table.tbl th,
table.tbl td{
  border:1px solid #d0d0d0;
  padding:.45rem .65rem;
  text-align:left;
  vertical-align:top;
}
table.tbl thead{background:#f5f7ff;}
.tbl .shape{
  font-family:"Roboto Mono",ui-monospace,monospace;
  white-space:nowrap;
}
.fact-table th{
  background:#f5f5f5;
  width:160px;
}

/* ----------  lead paragraph ---------- */
.lead{
  font-size:1.05rem;
  line-height:1.6;
  margin:1.2rem 0 2rem 0;
  color:#333;
}
.lead ul{margin:.6rem 0 .6rem 1.4rem}

/* ----------  bridge note ---------- */
.bridge{
  font-size:.95rem;
  margin:.8rem 0 1.1rem 0;
  color:#444;
}          

/* ----------  note paragraph ---------- */
.note {
  border-left: 3px solid #888;     /* subtle grey accent */
  padding: 0.6rem 1rem;
  margin: 1rem 0;
  background: #f9f9f9;             /* very light grey background */
  color: #333;                     /* dark text for readability */
  font-size: 0.97rem;
  line-height: 1.5;
}
.note strong {
  color: #000;                     /* bold keywords in pure black */
}

/* ----------  display equations ---------- */
.eq-scroll{
  display:block;
  overflow-x:auto;
  white-space:nowrap;
  text-align:center;
  margin:1.2rem auto;
  font-size:1.02rem;
}
@media(max-width:600px){
  .eq-scroll{font-size:.9rem}
  table.tbl{font-size:.9rem}
}

/* ----------  inline & block code ---------- */
code,pre{
  font-family:"Fira Code","SFMono-Regular",ui-monospace,monospace;
  font-size:.92rem;
}
code{
  background:#f3f4f6;
  color:#1a1a1a;
  padding:0 .25em;
  border-radius:4px;
}
pre{
  background:#f8f9fb;
  border:1px solid #cfd2d7;
  border-radius:6px;
  padding:.9rem 1rem;
  line-height:1.45;
  overflow-x:auto;
  margin:1.6rem 0;
}
pre code{background:none;padding:0}
@media(max-width:600px){
  pre{font-size:.82rem}
  code{font-size:.86rem}
}

/* ----------  GitHub-style code card ---------- */
.code-card{
  background:#f6f8fa;
  border:1px solid #d0d7de;
  border-radius:6px;
  overflow:hidden;
  margin:1.6rem 0;
}
.code-card .code-header{
  background:#eaeef2;
  border-bottom:1px solid #d0d7de;
  font:.75rem/1 system-ui,sans-serif;
  color:#24292f;
  padding:.45rem .9rem;
  text-transform:lowercase;
}
.code-card pre{
  margin:0;
  padding:.8rem 1rem;
  background:inherit;
  font-size:.92rem;
  white-space:pre;
}
@media(max-width:600px){
  .code-card pre{font-size:.82rem}
}
  
/* === let wide tables side-scroll on narrow screens === */
@media (max-width: 600px){
  table.tbl{
    display:block;          /* makes it a scroll container   */
    overflow-x:auto;        /* side-scroll if too wide        */
    -webkit-overflow-scrolling: touch;
  }
  table.tbl thead,
  table.tbl tbody{
    display:table;          /* keeps header & body aligned    */
    width:100%;
  }
  table.tbl th,
  table.tbl td{
    white-space:nowrap;     /* prevent ugly line wraps        */
  }
}

/* ----------  Responsive heading wraps & scaling ---------- */

/* Allow long words in headings to break */
h1, h2, h3, h4, h5, h6 {
  overflow-wrap: break-word;
  word-wrap: break-word;
  hyphens: auto;
  white-space: normal;       /* override any no-wrap */
}

/* Shrink heading text on narrow viewports */
@media (max-width: 600px) {
  h1 { font-size: 1.5rem; }
  h2 { font-size: 1.3rem; }
  h3 { font-size: 1.15rem; }
  /* you can add h4, h5 as needed */
}

/* Optional: make the entire page text flow better on mobile */
body {
  word-wrap: break-word;
  overflow-wrap: break-word;
}

/* Override scroll-to-top button on mobile so it never hangs off-screen */
#scrollTopBtn {
  /* default for desktop */
  bottom: 2rem;
  right: 2rem;
}

/* on small viewports, reduce the offsets & size */
@media (max-width: 600px) {
  #scrollTopBtn {
    bottom: 1rem !important;
    right: 1rem !important;
    padding: 0.4rem 0.6rem !important;
    font-size: 1rem !important;
    max-width: 2.5rem;    /* ensure it stays compact */
    max-height: 2.5rem;
  }
}



</style>


<!-- ========== Blog Title ========== -->
<h1 id="heading">
  Continuous-Time Diffusion Models: SDE Formulations and Variational Objectives
</h1>

<!-- ========== TL;DR Summary (plain inline equations) ========== -->
<aside class="tldr">
  <h2 id="TL;DR">TL;DR</h2>
  <p>
    This post extends our mathematical journey into diffusion models, moving beyond discrete timesteps to a continuous-time framework:
  </p>
  <ol>
    <li><strong>Continuous SDEs:</strong> Generalize discrete forward/reverse processes to stochastic differential equations of the form dx_t = f(x, t) dt + g(t) dB_t.</li>
    <li><strong>Noise Schedules:</strong> Map variance schedules beta(t) to drift and diffusion coefficients.</li>
    <li><strong>Variational Objectives:</strong> Derive a continuous-time ELBO using Girsanov’s theorem and connect it to the Fisher information integral.</li>
    <li><strong>Score Matching:</strong> Interpret the loss as continuous-time score matching for learning nabla_x log p_t(x).</li>
    <li><strong>Outlook:</strong> Preview Predictor–Corrector samplers and deterministic probability flow ODEs for faster sampling.</li>
  </ol>
  <p>
    By the end, you’ll see how Song et al. (2021)’s framework unifies diffusion models under elegant continuous-time dynamics.
  </p>
</aside>

<!-- ========== 1. Introduction ========== -->
<h2 id="section-1">1. Introduction</h2>
<p class="lead">
  In our <a href="https://backpropthoughts.netlify.app/post?postId=stochastic-to-diffusion" target="_blank">previous post</a>, we traced the mathematical spine of diffusion models—from Brownian motion and Itô calculus to the discrete Denoising Diffusion Probabilistic Models (DDPM) framework. We derived the forward and reverse stochastic differential equations (SDEs), explored their connection to the Fokker–Planck PDE, and built up to the variational ELBO that makes DDPMs trainable in practice.
</p>

<p>
  To fully appreciate these ideas, it helps to recall our earlier post on 
  <a href="https://backpropthoughts.netlify.app/post?postId=diffusion-maths" target="_blank">denoising score matching</a>, where we examined how noise prediction relates to estimating the gradient of the data log-density. These insights form the foundation for the continuous-time perspective.
</p>

<p>
  While discrete diffusion models like DDPM are powerful, their reliance on fixed timesteps can be limiting. This motivates the transition to <strong>continuous-time diffusion models</strong>, where stochastic processes evolve in an unbroken time interval and neural networks learn to approximate the score function across all \(t \in [0, T]\).
</p>

<p class="bridge">
  In this post, we build on these foundations and dive into the continuous-time formulation. We will derive forward and reverse SDEs, map noise schedules \(\beta(t)\) to drift and diffusion coefficients, and show how Girsanov’s theorem leads naturally to a continuous-time ELBO. Along the way, we’ll see how the Fisher information emerges in this setting and why score-based generative models are a natural generalization of DDPMs.
</p>


<!-- ========== 2. Forward and Reverse SDEs ========== -->
<h2 id="section-2">2. Forward and Reverse SDEs</h2>

<p class="lead">
  In the <a href="https://backpropthoughts.netlify.app/post?postId=stochastic-to-diffusion" target="_blank">previous post</a>, we derived both the forward and reverse stochastic differential equations (SDEs) that form the backbone of diffusion models. Let’s briefly revisit these results to set the stage for continuous-time formulations.
</p>

<!-- ----- 2.1 Forward SDE ----- -->
<h3 id="section-2-1">2.1 Forward SDE</h3>
<p>
  The forward diffusion process incrementally perturbs a clean data sample \(x_0\) by adding Gaussian noise at each timestep. In the continuous-time limit, this is modeled by the SDE:
</p>

<div class="eq-scroll">
  (2.1)\;
  \(dx_t = f(x, t)\,dt + g(t)\,dB_t\)
</div>

<p>
  Here:
</p>
<ul>
  <li><strong>f(x, t):</strong> Drift function, capturing deterministic dynamics.</li>
  <li><strong>g(t):</strong> Diffusion coefficient, controlling the noise level.</li>
  <li><strong>dB_t:</strong> Brownian motion increment.</li>
</ul>

<p class="bridge">
  For a step-by-step derivation of this SDE from discrete Gaussian perturbations, see Section 2 of the <a href="https://backpropthoughts.netlify.app/post?postId=stochastic-to-diffusion" target="_blank">previous blog</a>.
</p>


<!-- ----- 2.2 Reverse SDE ----- -->
<h3 id="section-2-2">2.2 Reverse SDE</h3>
<p>
  To reverse the corruption process, we derived the reverse-time SDE (Anderson, 1982):
</p>

<div class="eq-scroll">
  (2.2)\;
  \(dx_t = [f(x, t) - g(t)^2 \nabla_x \log p_t(x)]\,dt + g(t)\,d\bar{B}_t\)
</div>

<p>
  The key insight is the additional drift term \(-g(t)^2 \nabla_x \log p_t(x)\), which steers noisy samples back toward high-density regions of the data distribution. In practice, we approximate \(\nabla_x \log p_t(x)\) with a neural network \(s_θ(x, t)\) trained via score matching.
</p>

<p class="note">
  <strong>Note:</strong> For the full derivation of this reverse SDE using the Fokker–Planck PDE and Itô calculus, refer to Section 4 in the <a href="https://backpropthoughts.netlify.app/post?postId=stochastic-to-diffusion" target="_blank">previous post</a>.
</p>

<!-- ========== 3. Noise Schedules and Drift/Diffusion Coefficients ========== -->
<h2 id="section-3">3. Noise Schedules and Drift/Diffusion Coefficients</h2>

<p class="lead">
  In discrete diffusion models like DDPM, we define a variance schedule \(\{\beta_t\}\) to control how much noise is added at each timestep. As we transition to continuous-time models, we replace this with a smooth function \(\beta(t)\) defined for \(t \in [0, T]\). This section shows how \(\beta(t)\) determines the drift \(f(x, t)\) and diffusion coefficient \(g(t)\) in the forward SDE.
</p>

<p>
  Recall the continuous forward SDE:
</p>

<div class="eq-scroll">
  (3.1)\;
  \(dx_t = f(x, t)\,dt + g(t)\,dB_t\)
</div>

<p>
  In most diffusion models, the drift is chosen to keep the process isotropic and centered, leading to:
</p>

<div class="eq-scroll">
  (3.2)\;
  \(f(x, t) = -\tfrac{1}{2}\,\beta(t)\,x\)
</div>

<p>
  The diffusion coefficient \(g(t)\) relates directly to \(\beta(t)\):
</p>

<div class="eq-scroll">
  (3.3)\;
  \(g(t) = \sqrt{\beta(t)}\)
</div>

<p class="bridge">
  Let’s derive these relationships starting from the discrete variance schedule.
</p>

<!-- ----- 3.1 From Discrete to Continuous ----- -->
<h3 id="section-3-1">3.1 From Discrete to Continuous</h3>
<p class="lead">
  In DDPM, the forward process is defined as:
</p>

<div class="eq-scroll">
  (3.4)\;
  \(x_t = \sqrt{1 - \beta_t}\,x_{t-1} + \sqrt{\beta_t}\,\epsilon_t,\; \epsilon_t \sim \mathcal{N}(0, I)\)
</div>

<p>
  For small \(\beta_t\), expand \(\sqrt{1 - \beta_t}\) using a first-order Taylor approximation:
</p>

<div class="eq-scroll">
  (3.5)\;
  \(\sqrt{1 - \beta_t} \approx 1 - \tfrac{1}{2}\,\beta_t\)
</div>

<p>
  Substituting back, we get:
</p>

<div class="eq-scroll">
  (3.6)\;
  \(x_t - x_{t-1} \approx -\tfrac{1}{2}\,\beta_t\,x_{t-1} + \sqrt{\beta_t}\,\epsilon_t\)
</div>

<p>
  Dividing both sides by \(\Delta t\) (where \(\Delta t = 1/T\), the timestep size) and taking the limit \(\Delta t \to 0\), we obtain the continuous-time forward SDE:
</p>

<div class="eq-scroll">
  (3.7)\;
  \(dx_t = -\tfrac{1}{2}\,\beta(t)\,x_t\,dt + \sqrt{\beta(t)}\,dB_t\)
</div>

<details>
  <summary><strong>Step-by-step derivation</strong></summary>
  <p>
    Starting from the discrete update:
  </p>

  <div class="eq-scroll">
    (3.8)\;
    \(x_t = \sqrt{1 - \beta_t}\,x_{t-1} + \sqrt{\beta_t}\,\epsilon_t\)
  </div>

  <p>
    Approximate \(\sqrt{1 - \beta_t} \approx 1 - \tfrac{1}{2}\,\beta_t\):
  </p>

  <div class="eq-scroll">
    (3.9)\;
    \(x_t \approx (1 - \tfrac{1}{2}\,\beta_t)\,x_{t-1} + \sqrt{\beta_t}\,\epsilon_t\)
  </div>

  <p>
    Simplify:
  </p>

  <div class="eq-scroll">
    (3.10)\;
    \(x_t - x_{t-1} \approx -\tfrac{1}{2}\,\beta_t\,x_{t-1} + \sqrt{\beta_t}\,\epsilon_t\)
  </div>

  <p>
    Divide by \(\Delta t\) and recognize limits:
  </p>

  <div class="eq-scroll">
    (3.11)\;
    \(\frac{x_t - x_{t-1}}{\Delta t} \to \frac{dx_t}{dt},\; \frac{\sqrt{\beta_t}}{\sqrt{\Delta t}} \to \sqrt{\beta(t)}\)
  </div>

  <p>
    Resulting in:
  </p>

  <div class="eq-scroll">
    (3.12)\;
    \(dx_t = -\tfrac{1}{2}\,\beta(t)\,x_t\,dt + \sqrt{\beta(t)}\,dB_t\)
  </div>
</details>

<p class="note">
  <strong>Key Insight:</strong> The drift term \(-\tfrac{1}{2}\,\beta(t)\,x_t\) pulls samples toward the origin, while the diffusion term \(\sqrt{\beta(t)}\) injects Gaussian noise.
</p>

<!-- ----- 3.2 Common Noise Schedules ----- -->
<h3 id="section-3-2">3.2 Common Noise Schedules</h3>
<p class="lead">
  The choice of \(\beta(t)\) profoundly affects training stability and sample quality. Common schedules include:
</p>

<ul>
  <li><strong>Linear:</strong> \(\beta(t)\) increases linearly from \(\beta_0\) to \(\beta_1\).</li>
  <li><strong>Cosine:</strong> \(\beta(t)\) follows a cosine curve for smoother noise accumulation (Nichol & Dhariwal, 2021).</li>
  <li><strong>Exponential:</strong> \(\beta(t) = \beta_0\,e^{\lambda t}\)</li>
</ul>

<p>
  Visualizing \(\beta(t)\) and the resulting diffusion coefficient \(g(t) = \sqrt{\beta(t)}\) helps understand their impact.
</p>

<figure>
  <img src="posts/continious-time-diffuision-models/assets/figure1.png" alt="Examples of noise schedules β(t)">
  <figcaption>
    <strong>Figure 1:</strong> Common noise schedules used in continuous-time diffusion models. Linear schedules steadily increase noise, while cosine schedules emphasize early timesteps.
  </figcaption>
</figure>

<p class="note">
  <strong>Takeaway:</strong> Carefully designing \(\beta(t)\) balances noise injection across time, crucial for stable training.
</p>


<!-- ========== 4. Training Objective in Continuous Time ========== -->
<h2 id="section-4">4. Training Objective in Continuous Time</h2>

<p class="lead">
  In discrete diffusion models, we derived the variational lower bound (ELBO) using KL divergences between Gaussian distributions at each timestep. For continuous-time diffusion models, we need more advanced stochastic calculus—specifically <strong>Girsanov’s theorem</strong>—to handle the change of measure between the forward and reverse SDEs.
</p>

<p>
  Recall the forward SDE:
</p>

<div class="eq-scroll">
  (4.1)\;
  \(dx_t = f(x, t)\,dt + g(t)\,dB_t\)
</div>

<p>
  and the reverse SDE:
</p>

<div class="eq-scroll">
  (4.2)\;
  \(dx_t = [f(x, t) - g(t)^2 \nabla_x \log p_t(x)]\,dt + g(t)\,d\bar{B}_t\)
</div>

<p class="bridge">
  Our goal is to find a tractable objective for training a neural network \(s_\theta(x, t) \approx \nabla_x \log p_t(x)\) that approximates the score function.
</p>


<!-- ----- 4.1 Girsanov’s Theorem ----- -->
<h3 id="section-4-1">4.1 Girsanov’s Theorem</h3>
<p class="lead">
  Girsanov’s theorem gives the Radon–Nikodym derivative (likelihood ratio) between two probability measures induced by different SDEs.
</p>

<p>
  Consider two SDEs with the same diffusion coefficient \(g(t)\):
</p>

<div class="eq-scroll">
  (4.3)\;
  \(dx_t = f(x, t)\,dt + g(t)\,dB_t\)
</div>

<p>
  and
</p>

<div class="eq-scroll">
  (4.4)\;
  \(dx_t = \tilde{f}(x, t)\,dt + g(t)\,d\tilde{B}_t\)
</div>

<p>
  Girsanov’s theorem tells us:
</p>

<div class="eq-scroll">
  (4.5)\;
  \[
  \frac{d\mathbb{Q}}{d\mathbb{P}} = \exp\left(
    \int_0^T \frac{\tilde{f}(x, t) - f(x, t)}{g(t)}\,dB_t
    - \frac{1}{2} \int_0^T \left\|\frac{\tilde{f}(x, t) - f(x, t)}{g(t)}\right\|^2 dt
  \right)
  \]
</div>

<details>
  <summary><strong>Step-by-step derivation of likelihood ratio</strong></summary>
  <p>
    Define the drift difference:
  </p>

  <div class="eq-scroll">
    (4.6)\;
    \(\delta(x, t) = \frac{\tilde{f}(x, t) - f(x, t)}{g(t)}\)
  </div>

  <p>
    Substituting \(\delta(x, t)\) gives:
  </p>

  <div class="eq-scroll">
    (4.7)\;
    \[
    \frac{d\mathbb{Q}}{d\mathbb{P}} = \exp\left(
      \int_0^T \delta(x, t)\,dB_t
      - \frac{1}{2}\int_0^T \|\delta(x, t)\|^2 dt
    \right)
    \]
  </div>
</details>

<p class="note">
  <strong>Key Insight:</strong> This change-of-measure underpins the derivation of continuous-time variational objectives.
</p>


<!-- ----- 4.2 ELBO Derivation ----- -->
<h3 id="section-4-2">4.2 ELBO Derivation</h3>
<p class="lead">
  To train the reverse model, we minimize the KL divergence between the true forward process \(q\) and the parameterized reverse process \(p_\theta\):
</p>

<div class="eq-scroll">
  (4.8)\;
  \(\mathrm{KL}(q \| p_\theta) = \mathbb{E}_{q}\left[\log\frac{q(x_{0:T})}{p_\theta(x_{0:T})}\right]\)
</div>

<p>
  Using Girsanov’s theorem, this simplifies to:
</p>

<div class="eq-scroll">
  (4.9)\;
  \[
  \mathrm{KL}(q \| p_\theta) = \mathbb{E}_q\left[\frac{1}{2}\int_0^T \|s_\theta(x, t) - \nabla_x \log p_t(x)\|^2 g(t)^2\,dt\right] + C
  \]
</div>

<p class="bridge">
  Here, \(C\) is a constant independent of \(\theta\), and \(s_\theta(x, t)\) approximates \(\nabla_x \log p_t(x)\).
</p>


<!-- ----- 4.3 Fisher Information Integral ----- -->
<h3 id="section-4-3">4.3 Fisher Information Integral</h3>
<p class="lead">
  Notice the appearance of the Fisher information weighted by \(g(t)^2\):
</p>

<div class="eq-scroll">
  (4.10)\;
  \[
  \int_0^T g(t)^2 \mathbb{E}_{p_t(x)}\left[\|s_\theta(x, t) - \nabla_x \log p_t(x)\|^2\right]\,dt
  \]
</div>

<p>
  Minimizing this term is equivalent to matching the network’s score predictions to the true score at every time \(t\).
</p>

<p class="note">
  <strong>Takeaway:</strong> This weighted error forms the continuous-time denoising score matching objective.
</p>


<!-- ----- 4.4 Summary ----- -->
<h3 id="section-4-4">4.4 Summary</h3>
<p class="lead">
  Using Girsanov’s theorem, we derive a continuous-time ELBO that unifies stochastic calculus and variational inference. The resulting objective trains the model to learn \(\nabla_x \log p_t(x)\) across all noise levels.
</p>

<figure>
  <img src="posts/continious-time-diffuision-models/assets/figure2.png" alt="Continuous-time ELBO schematic">
  <figcaption>
    <strong>Figure 2:</strong> Schematic of the continuous-time ELBO derived via Girsanov’s theorem.
  </figcaption>
</figure>


<!-- ========== 5. Implications for Score Matching ========== -->
<h2 id="section-5">5. Implications for Score Matching</h2>

<p class="lead">
  The continuous-time variational objective derived earlier connects beautifully to <strong>denoising score matching</strong>, originally proposed by Vincent (2011). Let’s unpack this connection step by step and relate it to diffusion models.
</p>

<p>
  Recall the continuous-time loss:
</p>

<div class="eq-scroll">
  (5.1)\;
  \[
  L(\theta) = \int_0^T g(t)^2\, \mathbb{E}_{p_t(x)}\left[\|s_\theta(x, t) - \nabla_x \log p_t(x)\|^2\right]\, dt
  \]
</div>

<p class="bridge">
  This objective encourages the neural network \(s_\theta(x, t)\) to approximate the true score function \(\nabla_x \log p_t(x)\) at every \(t \in [0, T]\).
</p>


<!-- ----- 5.1 Score Matching Recap ----- -->
<h3 id="section-5-1">5.1 Score Matching Recap</h3>
<p class="lead">
  Score matching minimizes the expected squared error between the model’s score estimate and the true score:
</p>

<div class="eq-scroll">
  (5.2)\;
  \[
  \mathcal{J}(\theta) = \mathbb{E}_{p(x)}\left[\|\nabla_x \log p(x) - s_\theta(x)\|^2\right]
  \]
</div>

<p>
  In diffusion models, this idea extends across a continuum of noise levels \(t \in [0, T]\).
</p>

<p class="note">
  <strong>Reference:</strong> See our <a href="https://backpropthoughts.netlify.app/post?postId=diffusion-maths" target="_blank">earlier post on score matching</a> for a full derivation and motivation.
</p>


<!-- ----- 5.2 Derivation: From ELBO to Score Matching ----- -->
<h3 id="section-5-2">5.2 From ELBO to Score Matching</h3>
<p class="lead">
  Let’s expand the continuous-time ELBO step by step to see its equivalence to score matching.
</p>

<details>
  <summary><strong>Step-by-step derivation</strong></summary>

  <p>
    Start with the KL divergence between \(q(x_{0:T})\) and \(p_\theta(x_{0:T})\):
  </p>

  <div class="eq-scroll">
    (5.3)\;
    \[
    \mathrm{KL}(q \| p_\theta) = \mathbb{E}_q\left[\log\frac{q(x_{0:T})}{p_\theta(x_{0:T})}\right]
    \]
  </div>

  <p>
    Applying Girsanov’s theorem, we rewrite this as:
  </p>

  <div class="eq-scroll">
    (5.4)\;
    \[
    \log\frac{q(x_{0:T})}{p_\theta(x_{0:T})} = \frac{1}{2}\int_0^T \|s_\theta(x, t) - \nabla_x \log p_t(x)\|^2 g(t)^2\, dt + C
    \]
  </div>

  <p>
    Here \(C\) is a constant independent of \(\theta\).
  </p>

  <p>
    Taking expectations gives:
  </p>

  <div class="eq-scroll">
    (5.5)\;
    \[
    L(\theta) = \frac{1}{2}\int_0^T g(t)^2\, \mathbb{E}_{p_t(x)}\left[\|s_\theta(x, t) - \nabla_x \log p_t(x)\|^2\right]\, dt + C
    \]
  </div>
</details>

<p class="note">
  <strong>Key Insight:</strong> Minimizing \(L(\theta)\) matches the predicted score to the true score across all time \(t\).
</p>


<!-- ----- 5.3 Discrete DDPM Loss Connection ----- -->
<h3 id="section-5-3">5.3 Discrete DDPM Loss Connection</h3>
<p class="lead">
  In discrete diffusion models, Ho et al. (2020) use the simplified loss:
</p>

<div class="eq-scroll">
  (5.6)\;
  \[
  L_{\text{simple}}(\theta) = \mathbb{E}_{t, x_0, \epsilon}\left[
    \|\epsilon - \epsilon_\theta(x_t, t)\|^2
  \right]
  \]
</div>

<p>
  where \(\epsilon_\theta(x_t, t)\) predicts the noise added at timestep \(t\).
</p>

<p>
  This is a special case of score matching since:
</p>

<div class="eq-scroll">
  (5.7)\;
  \[
  \epsilon = -g(t)\,\nabla_x \log p_t(x) + \mathcal{N}(0, I)
  \]
</div>

<p>
  Training \(\epsilon_\theta\) to predict \(\epsilon\) indirectly learns the score \(\nabla_x \log p_t(x)\).
</p>

<p class="bridge">
  In continuous time, we directly train \(s_\theta(x, t)\) to approximate \(\nabla_x \log p_t(x)\).
</p>


<!-- ----- 5.4 Summary ----- -->
<h3 id="section-5-4">5.4 Summary</h3>
<p class="lead">
  The continuous-time variational loss reduces to denoising score matching over the entire diffusion trajectory.
</p>

<p class="note">
  <strong>Takeaway:</strong> This elegant connection generalizes discrete DDPM objectives to the continuous domain.
</p>


<!-- ========== 6. Continuous-Time Loss Interpretation ========== -->
<h2 id="section-6">6. Continuous-Time Loss Interpretation</h2>

<p class="lead">
  The continuous-time training objective integrates a time-weighted error over all noise levels \(t \in [0, T]\). Understanding how this loss distributes across time is key to designing effective noise schedules \(\beta(t)\) and samplers.
</p>

<p>
  Recall the continuous-time loss:
</p>

<div class="eq-scroll">
  (6.1)\;
  \[
  L(\theta) = \int_0^T g(t)^2\, \mathbb{E}_{p_t(x)}\left[\|s_\theta(x, t) - \nabla_x \log p_t(x)\|^2\right]\, dt
  \]
</div>

<p>
  Here, \(g(t)^2\) weights the contribution of each time \(t\) to the total loss.
</p>


<!-- ----- 6.1 Time-Weighted Loss Density ----- -->
<h3 id="section-6-1">6.1 Time-Weighted Loss Density</h3>
<p class="lead">
  Define the instantaneous loss density \(\ell(t)\) as:
</p>

<div class="eq-scroll">
  (6.2)\;
  \[
  \ell(t) = g(t)^2\, \mathbb{E}_{p_t(x)}\left[\|s_\theta(x, t) - \nabla_x \log p_t(x)\|^2\right]
  \]
</div>

<p>
  The total loss integrates \(\ell(t)\) over the interval \([0, T]\):
</p>

<div class="eq-scroll">
  (6.3)\;
  \[
  L(\theta) = \int_0^T \ell(t)\, dt
  \]
</div>

<p class="note">
  <strong>Key Insight:</strong> \(\ell(t)\) shows how error is distributed along the diffusion trajectory.
</p>


<!-- ----- 6.2 Early vs. Late Time Contributions ----- -->
<h3 id="section-6-2">6.2 Early vs. Late Time Contributions</h3>
<p class="lead">
  Consider two noise schedules:
</p>
<ul>
  <li><strong>Linear schedule:</strong> \(\beta(t)\) grows linearly over time.</li>
  <li><strong>Cosine schedule:</strong> \(\beta(t)\) follows a cosine curve, emphasizing earlier timesteps.</li>
</ul>

<p>
  In a linear schedule, late times dominate \(\ell(t)\) since \(g(t)^2\) grows with time. Conversely, cosine schedules redistribute weight toward early times, focusing learning where data retains structure.
</p>

<details>
  <summary><strong>Why does \(g(t)^2\) emphasize late times?</strong></summary>
  <p>
    Since \(g(t)^2 = \beta(t)\), a linear \(\beta(t)\) means \(g(t)^2\) grows proportionally with time. Errors at high noise levels contribute more to \(L(\theta)\).
  </p>
</details>

<p class="note">
  <strong>Takeaway:</strong> Cosine schedules balance learning across noise levels, leading to better sample quality.
</p>


<!-- ----- 6.3 Fisher Information Perspective ----- -->
<h3 id="section-6-3">6.3 Fisher Information Perspective</h3>
<p class="lead">
  Recall the Fisher information at time \(t\):
</p>

<div class="eq-scroll">
  (6.4)\;
  \[
  \mathcal{I}(t) = \mathbb{E}_{p_t(x)}\left[\|\nabla_x \log p_t(x)\|^2\right]
  \]
</div>

<p>
  The loss can be viewed as a Fisher-weighted score error:
</p>

<div class="eq-scroll">
  (6.5)\;
  \[
  L(\theta) = \int_0^T g(t)^2\, \mathcal{I}(t)\, dt
  \]
</div>

<p>
  This highlights how noise schedules determine which regions of \(t\) are emphasized during training.
</p>


<!-- ----- 6.4 Summary ----- -->
<h3 id="section-6-4">6.4 Summary</h3>
<p class="lead">
  The continuous-time loss explains why the choice of \(\beta(t)\) affects model focus during training. Balancing \(\ell(t)\) across \(t\) is crucial for effective score learning.
</p>

<p class="note">
  <strong>Key Takeaway:</strong> Visualizing \(\ell(t)\) helps in designing noise schedules and sampling strategies tailored to model capacity.
</p>


<!-- ========== 7. SDE and ODE Duality: Probability Flow Perspective ========== -->
<h2 id="section-7">7. SDE and ODE Duality: Probability Flow Perspective</h2>

<p class="lead">
  So far, we’ve described the reverse-time SDE for sampling. But stochasticity isn’t mandatory: there exists a deterministic counterpart—the <strong>probability flow ODE</strong>—that preserves the marginal distributions \(p_t(x)\) without noise.
</p>

<p>
  This duality between SDE and ODE is a cornerstone of continuous-time diffusion models. Let’s derive the probability flow ODE step by step.
</p>


<!-- ----- 7.1 The Reverse-Time SDE (Recap) ----- -->
<h3 id="section-7-1">7.1 The Reverse-Time SDE (Recap)</h3>
<p class="lead">
  Recall the reverse-time SDE (Anderson, 1982):
</p>

<div class="eq-scroll">
  (7.1)\;
  \[
  dx_t = \big[f(x_t, t) - g(t)^2 \nabla_x \log p_t(x)\big]\, dt + g(t)\, d\bar{B}_t
  \]
</div>

<p>
  where:
</p>
<ul>
  <li>\(f(x, t)\): drift of the forward SDE</li>
  <li>\(g(t)\): diffusion coefficient</li>
  <li>\(d\bar{B}_t\): reverse-time Brownian motion increment</li>
</ul>

<p class="bridge">
  To find a deterministic equivalent, we examine the Fokker–Planck PDE of this SDE.
</p>


<!-- ----- 7.2 Fokker–Planck PDE for the Reverse SDE ----- -->
<h3 id="section-7-2">7.2 Fokker–Planck PDE for the Reverse SDE</h3>
<p class="lead">
  The evolution of \(p_t(x)\) under the reverse SDE satisfies:
</p>

<div class="eq-scroll">
  (7.2)\;
  \[
  \partial_t p_t(x) = -\nabla_x \cdot \left(\mu(x, t)p_t(x)\right) + \frac{1}{2}g(t)^2\Delta_x p_t(x)
  \]
</div>

<p>
  where:
</p>
<ul>
  <li>\(\mu(x, t) = f(x, t) - g(t)^2 \nabla_x \log p_t(x)\): drift term</li>
  <li>\(\Delta_x\): Laplacian operator in \(x\)</li>
</ul>

<details>
  <summary><strong>Derivation of the PDE</strong></summary>
  <p>
    Starting from the reverse SDE:
  </p>

  <div class="eq-scroll">
    \[
    dx_t = \mu(x, t)\, dt + g(t)\, d\bar{B}_t
    \]
  </div>

  <p>
    The Fokker–Planck PDE is given by:
  </p>

  <div class="eq-scroll">
    \[
    \partial_t p_t(x) = -\nabla_x \cdot [\mu(x, t)p_t(x)] + \tfrac{1}{2}g(t)^2\Delta_x p_t(x)
    \]
  </div>
</details>

<p class="note">
  <strong>Key Insight:</strong> The PDE has two terms—drift (transport) and diffusion (randomness).
</p>


<!-- ----- 7.3 Deterministic Flow: Dropping Diffusion ----- -->
<h3 id="section-7-3">7.3 Deterministic Flow: Dropping Diffusion</h3>
<p class="lead">
  To get a deterministic system, we drop the diffusion term (\(\tfrac{1}{2}g(t)^2\Delta_x p_t(x)\)). The resulting continuity equation is:
</p>

<div class="eq-scroll">
  (7.3)\;
  \[
  \partial_t p_t(x) = -\nabla_x \cdot (v(x, t)p_t(x))
  \]
</div>

<p>
  where \(v(x, t)\) is a deterministic velocity field.
</p>

<p class="bridge">
  To match the drift term of the reverse SDE, set:
</p>

<div class="eq-scroll">
  (7.4)\;
  \[
  v(x, t) = f(x, t) - g(t)^2 \nabla_x \log p_t(x)
  \]
</div>


<!-- ----- 7.4 The Probability Flow ODE ----- -->
<h3 id="section-7-4">7.4 The Probability Flow ODE</h3>
<p class="lead">
  The deterministic probability flow ODE is then:
</p>

<div class="eq-scroll">
  (7.5)\;
  \[
  \frac{dx}{dt} = f(x, t) - g(t)^2 s_\theta(x, t)
  \]
</div>

<p>
  where \(s_\theta(x, t)\) approximates \(\nabla_x \log p_t(x)\) with a neural network.
</p>

<p class="note">
  <strong>Key Insight:</strong> This ODE traces deterministic trajectories matching the marginals of the reverse SDE.
</p>


<!-- ----- 7.5 Summary ----- -->
<h3 id="section-7-5">7.5 Summary</h3>
<p class="lead">
  The probability flow ODE is a deterministic alternative to the reverse SDE. It avoids stochasticity while preserving the density evolution \(p_t(x)\).
</p>

<p class="note">
  <strong>Essential Takeaway:</strong> SDE and ODE are two sides of the same coin: stochastic and deterministic sampling in continuous-time diffusion models.
</p>



<!-- ========== 8. Predictor–Corrector Samplers ========== -->
<h2 id="section-8">8. Predictor–Corrector Samplers</h2>

<p class="lead">
  While the probability flow ODE enables deterministic sampling, stochasticity can be desirable for diversity and robustness. To combine the strengths of both approaches, Song et al. (2021) introduced <strong>Predictor–Corrector (PC) samplers</strong>. These alternate between deterministic and stochastic steps to generate high-quality samples.
</p>

<p>
  The PC sampler consists of:
</p>
<ul>
  <li><strong>Predictor steps:</strong> Deterministic updates using a discretized reverse SDE.</li>
  <li><strong>Corrector steps:</strong> Stochastic refinements using Langevin Dynamics.</li>
</ul>

<p class="bridge">
  Let’s derive and explain each step in detail.
</p>


<!-- ----- 8.1 Predictor Step (Discretized SDE) ----- -->
<h3 id="section-8-1">8.1 Predictor Step (Discretized SDE)</h3>
<p class="lead">
  The predictor step advances the sample along the reverse SDE using Euler–Maruyama discretization:
</p>

<div class="eq-scroll">
  (8.1)\;
  \[
  x_{t - \Delta t} = x_t + \left[f(x_t, t) - g(t)^2 s_\theta(x_t, t)\right]\Delta t + g(t)\sqrt{\Delta t}\, z
  \]
</div>

<p>
  where:
</p>
<ul>
  <li>\(z \sim \mathcal{N}(0, I)\): standard Gaussian noise</li>
  <li>\(\Delta t\): step size</li>
</ul>

<details>
  <summary><strong>Step-by-step breakdown</strong></summary>
  <p>
    Compute the drift term:
  </p>
  <div class="eq-scroll">
    \[
    \mu(x_t, t) = f(x_t, t) - g(t)^2 s_\theta(x_t, t)
    \]
  </div>

  <p>
    Compute the diffusion term:
  </p>
  <div class="eq-scroll">
    \[
    \sigma(x_t, t) = g(t)\sqrt{\Delta t}
    \]
  </div>

  <p>
    Update:
  </p>
  <div class="eq-scroll">
    \[
    x_{t - \Delta t} = x_t + \mu(x_t, t)\Delta t + \sigma(x_t, t)z
    \]
  </div>
</details>

<p class="note">
  <strong>Key Point:</strong> The predictor step alone corresponds to simulating the reverse SDE trajectory.
</p>


<!-- ----- 8.2 Corrector Step (Langevin Dynamics) ----- -->
<h3 id="section-8-2">8.2 Corrector Step (Langevin Dynamics)</h3>
<p class="lead">
  The corrector step applies Langevin Dynamics to refine samples and reduce errors:
</p>

<div class="eq-scroll">
  (8.2)\;
  \[
  x_t^{(k+1)} = x_t^{(k)} + \epsilon s_\theta(x_t^{(k)}, t) + \sqrt{2\epsilon}\, z
  \]
</div>

<p>
  where:
</p>
<ul>
  <li>\(\epsilon\): Langevin step size</li>
  <li>\(z \sim \mathcal{N}(0, I)\): Gaussian noise</li>
</ul>

<details>
  <summary><strong>Why Langevin Dynamics?</strong></summary>
  <p>
    Langevin Dynamics performs MCMC sampling from the distribution defined by \(s_\theta(x, t)\):
  </p>

  <div class="eq-scroll">
    \[
    dx = s_\theta(x, t)\, dt + \sqrt{2}\, dB_t
    \]
  </div>

  <p>
    Discretizing yields the update above.
  </p>
</details>

<p class="note">
  <strong>Key Point:</strong> The corrector step denoises while maintaining sample diversity through small stochastic perturbations.
</p>


<!-- ----- 8.3 Combined Predictor–Corrector Algorithm ----- -->
<h3 id="section-8-3">8.3 Combined Predictor–Corrector Algorithm</h3>
<p class="lead">
  The PC sampler alternates predictor and corrector steps from \(t = T\) down to \(t = 0\):
</p>

<ol>
  <li>Initialize \(x_T \sim \mathcal{N}(0, I)\).</li>
  <li>For each timestep \(t_i\) (from large to small):</li>
  <ol>
    <li>Perform \(K\) corrector steps (Langevin updates).</li>
    <li>Perform one predictor step (Euler–Maruyama update).</li>
  </ol>
  <li>Return \(x_0\) as the generated sample.</li>
</ol>

<figure>
  <img src="posts/continious-time-diffuision-models/assets/figure3.png" alt="Predictor–Corrector Sampler Diagram">
  <figcaption>
    <strong>Figure 3:</strong> Predictor–Corrector sampler alternates Langevin correction (dotted arrows) with SDE updates (solid arrows).
  </figcaption>
</figure>

<p class="note">
  <strong>Key Takeaway:</strong> PC samplers balance accuracy and stochasticity for robust sampling.
</p>


<!-- ----- 8.4 Summary ----- -->
<h3 id="section-8-4">8.4 Summary</h3>
<p class="lead">
  Predictor–Corrector samplers combine deterministic and stochastic updates to navigate the reverse diffusion process effectively. This hybrid approach produces diverse, high-quality samples in continuous-time diffusion models.
</p>


<!-- ========== 9. Outlook: Beyond Continuous-Time Diffusion ========== -->
<h2 id="outlook">9. Outlook: Beyond Continuous-Time Diffusion</h2>

<p class="lead">
  Continuous-time diffusion models unify stochastic processes, variational inference, and score-based learning under one elegant mathematical framework. But this is far from the end of the story. Let’s briefly survey where these ideas lead next.
</p>

<!-- ----- 9.1 Deterministic Sampling with DDIM ----- -->
<h3 id="ddim">9.1 Deterministic Sampling with DDIM</h3>
<p class="lead">
  In discrete models, Ho et al. (2020) introduced Denoising Diffusion Implicit Models (DDIM) as a deterministic alternative to stochastic DDPM sampling.
</p>

<p>
  DDIM can be viewed as a non-stochastic discretization of the probability flow ODE derived in Section 7:
</p>

<div class="eq-scroll">
  \[
    \frac{dx}{dt} = f(x, t) - \tfrac{1}{2}g(t)^2 s_\theta(x, t)
  \]
</div>

<p>
  By dropping the stochastic term \(g(t)dB_t\), DDIM produces deterministic trajectories that still approximate the data distribution. This enables faster sampling with fewer steps, though at the cost of sample diversity.
</p>

<p class="note">
  <strong>Key Insight:</strong> DDIM is effectively an ODE solver applied to the probability flow field.
</p>

<!-- ----- 9.2 Advanced Samplers: Consistency Models and Beyond ----- -->
<h3 id="consistency-models">9.2 Advanced Samplers: Consistency Models and Beyond</h3>
<p class="lead">
  Recent work explores even faster samplers and training paradigms. <strong>Consistency models</strong> (Song et al., 2023) train a neural network to predict denoised samples directly at arbitrary noise levels.
</p>

<p>
  The idea is to approximate the solution map of the probability flow ODE:
</p>

<div class="eq-scroll">
  \[
    \Phi_{t_0 \to t_1}(x_{t_0}) \approx x_{t_1}
  \]
</div>

<p>
  This avoids the need for iterative sampling entirely, enabling one-shot generation of high-quality samples.
</p>

<p class="note">
  <strong>Takeaway:</strong> Consistency models leverage the continuous-time view to create efficient, plug-and-play samplers.
</p>

<!-- ----- 9.3 Connections to Other Generative Models ----- -->
<h3 id="connections">9.3 Connections to Other Generative Models</h3>
<p class="lead">
  Continuous-time diffusion models also connect to other generative frameworks:
</p>
<ul>
  <li><strong>Normalizing Flows:</strong> The probability flow ODE defines a continuous flow of densities, akin to continuous normalizing flows.</li>
  <li><strong>Energy-Based Models:</strong> Score-based learning estimates \(\nabla_x \log p(x)\), the same object optimized in EBMs.</li>
  <li><strong>Generative Adversarial Networks (GANs):</strong> Both frameworks transport noise to data distributions, though GANs lack the explicit density modeling of diffusion processes.</li>
</ul>

<p class="bridge">
  These connections suggest a broader unification of generative modeling under the lens of differential equations.
</p>

<!-- ----- 9.4 Summary and Future Directions ----- -->
<h3 id="outlook-summary">9.4 Summary and Future Directions</h3>
<p class="lead">
  Continuous-time diffusion models open doors to faster sampling, novel training methods, and deep connections across generative modeling. As research advances, we anticipate:
</p>
<ul>
  <li>Hybrid SDE-ODE solvers for adaptive sampling.</li>
  <li>New parameterizations of score functions for stability.</li>
  <li>Applications to domains beyond images, such as molecular modeling and speech synthesis.</li>
</ul>

<p class="note">
  <strong>Essential Takeaway:</strong> The continuous-time perspective is not just a mathematical curiosity—it’s a foundation for the next generation of generative models.
</p>

